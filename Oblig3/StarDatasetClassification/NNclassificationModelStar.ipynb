{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import normalize\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dense, Input, Dropout\n",
    "from scikeras.wrappers import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\marku\\Desktop\\ML\\MLGit\\datasets\\Star.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "features = df.drop('Star type',axis=1)\n",
    "targets = df['Star type']\n",
    "\n",
    "targets_onehot = pd.get_dummies(targets)\n",
    "features_onehot = pd.get_dummies(features)\n",
    "targets_onehot = targets_onehot.astype('float32')\n",
    "features_onehot = features_onehot.astype('float32')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "features_onehot = normalize(features_onehot)\n",
    "\n",
    "train_features, test_features, train_targets, test_targets = train_test_split(features_onehot, targets_onehot, test_size=0.25, random_state=42)\n",
    "\n",
    "train_features_tensor = tf.convert_to_tensor(train_features, dtype=tf.float32)\n",
    "test_features_tensor = tf.convert_to_tensor(test_features, dtype=tf.float32)\n",
    "train_targets_tensor = tf.convert_to_tensor(train_targets, dtype=tf.int32)\n",
    "test_targets_tensor = tf.convert_to_tensor(test_targets, dtype=tf.int32)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# NN Architecture 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.7813 - accuracy: 0.1389\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.7484 - accuracy: 0.2056\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.6890 - accuracy: 0.3167\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.5800 - accuracy: 0.3167\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.4261 - accuracy: 0.3167\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.3013 - accuracy: 0.3389\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.2417 - accuracy: 0.3556\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.2088 - accuracy: 0.3833\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.2019 - accuracy: 0.3556\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1869 - accuracy: 0.3667\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1823 - accuracy: 0.3056\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1708 - accuracy: 0.3778\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.1710 - accuracy: 0.3778\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1640 - accuracy: 0.3556\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.1529 - accuracy: 0.4056\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.1449 - accuracy: 0.3500\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.1464 - accuracy: 0.4056\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.1579 - accuracy: 0.3611\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1318 - accuracy: 0.3944\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1433 - accuracy: 0.3389\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1504 - accuracy: 0.3333\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.1292 - accuracy: 0.3778\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1468 - accuracy: 0.3944\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1527 - accuracy: 0.3833\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1421 - accuracy: 0.3667\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1293 - accuracy: 0.3667\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.1338 - accuracy: 0.3556\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1255 - accuracy: 0.4111\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1190 - accuracy: 0.3611\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.1157 - accuracy: 0.3833\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1098 - accuracy: 0.3944\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1066 - accuracy: 0.4111\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1113 - accuracy: 0.4111\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0951 - accuracy: 0.4167\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1035 - accuracy: 0.3889\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 1.0913 - accuracy: 0.4556\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0944 - accuracy: 0.3889\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1092 - accuracy: 0.3500\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.1029 - accuracy: 0.4333\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1013 - accuracy: 0.3944\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.0810 - accuracy: 0.4556\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0928 - accuracy: 0.4500\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0718 - accuracy: 0.4222\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0863 - accuracy: 0.4667\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0936 - accuracy: 0.3889\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.0909 - accuracy: 0.4444\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.0628 - accuracy: 0.4611\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.0688 - accuracy: 0.4222\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0813 - accuracy: 0.4833\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.0611 - accuracy: 0.4333\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.0628 - accuracy: 0.4389\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0790 - accuracy: 0.4500\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.0518 - accuracy: 0.4833\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0430 - accuracy: 0.4722\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.0533 - accuracy: 0.4278\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.0505 - accuracy: 0.4722\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0412 - accuracy: 0.4556\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0503 - accuracy: 0.4556\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.0501 - accuracy: 0.4667\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.0306 - accuracy: 0.4444\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0234 - accuracy: 0.4722\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.0052 - accuracy: 0.6056\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0012 - accuracy: 0.5444\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.0333 - accuracy: 0.4167\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.9904 - accuracy: 0.4833\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.9750 - accuracy: 0.6333\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.9831 - accuracy: 0.5667\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9915 - accuracy: 0.5889\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9871 - accuracy: 0.5056\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9600 - accuracy: 0.5944\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.9536 - accuracy: 0.6000\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9589 - accuracy: 0.5722\n",
      "Epoch 73/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.9327 - accuracy: 0.6389\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.9676 - accuracy: 0.5222\n",
      "Epoch 75/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9268 - accuracy: 0.6167\n",
      "Epoch 76/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.9285 - accuracy: 0.6333\n",
      "Epoch 77/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.9309 - accuracy: 0.6056\n",
      "Epoch 78/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9169 - accuracy: 0.5833\n",
      "Epoch 79/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8969 - accuracy: 0.6556\n",
      "Epoch 80/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.9010 - accuracy: 0.5722\n",
      "Epoch 81/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.8815 - accuracy: 0.6833\n",
      "Epoch 82/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8795 - accuracy: 0.5944\n",
      "Epoch 83/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9000 - accuracy: 0.5389\n",
      "Epoch 84/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8729 - accuracy: 0.6278\n",
      "Epoch 85/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8752 - accuracy: 0.5778\n",
      "Epoch 86/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8428 - accuracy: 0.6056\n",
      "Epoch 87/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.8544 - accuracy: 0.6111\n",
      "Epoch 88/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.8336 - accuracy: 0.6333\n",
      "Epoch 89/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8065 - accuracy: 0.6444\n",
      "Epoch 90/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8055 - accuracy: 0.7000\n",
      "Epoch 91/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8091 - accuracy: 0.6389\n",
      "Epoch 92/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7667 - accuracy: 0.7111\n",
      "Epoch 93/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7869 - accuracy: 0.6556\n",
      "Epoch 94/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8107 - accuracy: 0.5833\n",
      "Epoch 95/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7826 - accuracy: 0.6333\n",
      "Epoch 96/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7680 - accuracy: 0.6333\n",
      "Epoch 97/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.7461 - accuracy: 0.7278\n",
      "Epoch 98/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7211 - accuracy: 0.6889\n",
      "Epoch 99/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.7379 - accuracy: 0.6833\n",
      "Epoch 100/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7256 - accuracy: 0.7111\n",
      "Epoch 101/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7186 - accuracy: 0.6833\n",
      "Epoch 102/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7101 - accuracy: 0.7111\n",
      "Epoch 103/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6865 - accuracy: 0.7500\n",
      "Epoch 104/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.7228 - accuracy: 0.6611\n",
      "Epoch 105/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6792 - accuracy: 0.7389\n",
      "Epoch 106/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.7295 - accuracy: 0.7000\n",
      "Epoch 107/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6467 - accuracy: 0.7667\n",
      "Epoch 108/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6362 - accuracy: 0.7944\n",
      "Epoch 109/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6860 - accuracy: 0.7333\n",
      "Epoch 110/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6670 - accuracy: 0.6667\n",
      "Epoch 111/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6395 - accuracy: 0.7222\n",
      "Epoch 112/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6552 - accuracy: 0.7611\n",
      "Epoch 113/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6248 - accuracy: 0.7889\n",
      "Epoch 114/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6006 - accuracy: 0.7667\n",
      "Epoch 115/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6343 - accuracy: 0.7667\n",
      "Epoch 116/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5838 - accuracy: 0.8056\n",
      "Epoch 117/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5795 - accuracy: 0.8000\n",
      "Epoch 118/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5872 - accuracy: 0.7778\n",
      "Epoch 119/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5960 - accuracy: 0.7611\n",
      "Epoch 120/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5948 - accuracy: 0.7778\n",
      "Epoch 121/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5967 - accuracy: 0.7556\n",
      "Epoch 122/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6194 - accuracy: 0.7278\n",
      "Epoch 123/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6471 - accuracy: 0.6889\n",
      "Epoch 124/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5771 - accuracy: 0.7722\n",
      "Epoch 125/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5383 - accuracy: 0.8333\n",
      "Epoch 126/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5319 - accuracy: 0.8167\n",
      "Epoch 127/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5354 - accuracy: 0.7722\n",
      "Epoch 128/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5383 - accuracy: 0.8333\n",
      "Epoch 129/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5222 - accuracy: 0.8389\n",
      "Epoch 130/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5578 - accuracy: 0.7611\n",
      "Epoch 131/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5465 - accuracy: 0.7667\n",
      "Epoch 132/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5232 - accuracy: 0.8056\n",
      "Epoch 133/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5301 - accuracy: 0.7889\n",
      "Epoch 134/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4992 - accuracy: 0.8056\n",
      "Epoch 135/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5689 - accuracy: 0.7222\n",
      "Epoch 136/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5309 - accuracy: 0.7944\n",
      "Epoch 137/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5157 - accuracy: 0.8056\n",
      "Epoch 138/200\n",
      "18/18 [==============================] - 0s 996us/step - loss: 0.4809 - accuracy: 0.8333\n",
      "Epoch 139/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4799 - accuracy: 0.8278\n",
      "Epoch 140/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4877 - accuracy: 0.8056\n",
      "Epoch 141/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4839 - accuracy: 0.8056\n",
      "Epoch 142/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4725 - accuracy: 0.8444\n",
      "Epoch 143/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5209 - accuracy: 0.8056\n",
      "Epoch 144/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4748 - accuracy: 0.8056\n",
      "Epoch 145/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4839 - accuracy: 0.8278\n",
      "Epoch 146/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4732 - accuracy: 0.8000\n",
      "Epoch 147/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4861 - accuracy: 0.8167\n",
      "Epoch 148/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4492 - accuracy: 0.8333\n",
      "Epoch 149/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4712 - accuracy: 0.8278\n",
      "Epoch 150/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4781 - accuracy: 0.7944\n",
      "Epoch 151/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4495 - accuracy: 0.8278\n",
      "Epoch 152/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4717 - accuracy: 0.7667\n",
      "Epoch 153/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4694 - accuracy: 0.8111\n",
      "Epoch 154/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5476 - accuracy: 0.7278\n",
      "Epoch 155/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4907 - accuracy: 0.7667\n",
      "Epoch 156/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4532 - accuracy: 0.8333\n",
      "Epoch 157/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4523 - accuracy: 0.7944\n",
      "Epoch 158/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4891 - accuracy: 0.7778\n",
      "Epoch 159/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4772 - accuracy: 0.8000\n",
      "Epoch 160/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4702 - accuracy: 0.8000\n",
      "Epoch 161/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4480 - accuracy: 0.8333\n",
      "Epoch 162/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4062 - accuracy: 0.8333\n",
      "Epoch 163/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4956 - accuracy: 0.8056\n",
      "Epoch 164/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4119 - accuracy: 0.8778\n",
      "Epoch 165/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4551 - accuracy: 0.8000\n",
      "Epoch 166/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4258 - accuracy: 0.8389\n",
      "Epoch 167/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4120 - accuracy: 0.8444\n",
      "Epoch 168/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3992 - accuracy: 0.8556\n",
      "Epoch 169/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4161 - accuracy: 0.8167\n",
      "Epoch 170/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4196 - accuracy: 0.8167\n",
      "Epoch 171/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4647 - accuracy: 0.7556\n",
      "Epoch 172/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4383 - accuracy: 0.8111\n",
      "Epoch 173/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4013 - accuracy: 0.8222\n",
      "Epoch 174/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4085 - accuracy: 0.8556\n",
      "Epoch 175/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3966 - accuracy: 0.8333\n",
      "Epoch 176/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4315 - accuracy: 0.8389\n",
      "Epoch 177/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4524 - accuracy: 0.7778\n",
      "Epoch 178/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5087 - accuracy: 0.7333\n",
      "Epoch 179/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4373 - accuracy: 0.8222\n",
      "Epoch 180/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4251 - accuracy: 0.8167\n",
      "Epoch 181/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4324 - accuracy: 0.8167\n",
      "Epoch 182/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5625 - accuracy: 0.7167\n",
      "Epoch 183/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3685 - accuracy: 0.8556\n",
      "Epoch 184/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3915 - accuracy: 0.8500\n",
      "Epoch 185/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3932 - accuracy: 0.8500\n",
      "Epoch 186/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3721 - accuracy: 0.8333\n",
      "Epoch 187/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3701 - accuracy: 0.8389\n",
      "Epoch 188/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3910 - accuracy: 0.8556\n",
      "Epoch 189/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4070 - accuracy: 0.8222\n",
      "Epoch 190/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.7889\n",
      "Epoch 191/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3577 - accuracy: 0.8611\n",
      "Epoch 192/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3602 - accuracy: 0.8667\n",
      "Epoch 193/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3965 - accuracy: 0.8222\n",
      "Epoch 194/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3426 - accuracy: 0.8667\n",
      "Epoch 195/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3769 - accuracy: 0.8611\n",
      "Epoch 196/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3795 - accuracy: 0.8500\n",
      "Epoch 197/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3488 - accuracy: 0.9056\n",
      "Epoch 198/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4102 - accuracy: 0.8167\n",
      "Epoch 199/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3681 - accuracy: 0.8444\n",
      "Epoch 200/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3525 - accuracy: 0.8444\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x19bb28b5c10>"
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "\n",
    "model1.add(Input(30))\n",
    "\n",
    "model1.add(Dense(30, activation='relu'))\n",
    "model1.add(Dense(30, activation='relu'))\n",
    "model1.add(Dense(30, activation='relu'))\n",
    "model1.add(Dense(30, activation='relu'))\n",
    "\n",
    "model1.add(Dense(6, activation='sigmoid'))\n",
    "\n",
    "opt1 = Adam()\n",
    "model1.compile(optimizer=opt1, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model1.fit(train_features_tensor, train_targets_tensor, epochs=200, batch_size=10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 1ms/step - loss: 0.3370 - accuracy: 0.8333\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.3369617164134979, 0.8333333134651184]"
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(train_features_tensor, train_targets_tensor)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3555 - accuracy: 0.8333\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.35553786158561707, 0.8333333134651184]"
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(test_features_tensor, test_targets_tensor)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "At first I had problems with the test accuracy outperforming the training accuracy. After changing the percent used for training/test this was mostly fixed."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Manuel Hyperparameter tuning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "15/15 [==============================] - 0s 857us/step - loss: 1.6981 - accuracy: 0.3167\n",
      "Epoch 2/200\n",
      "15/15 [==============================] - 0s 714us/step - loss: 1.5184 - accuracy: 0.3333\n",
      "Epoch 3/200\n",
      "15/15 [==============================] - 0s 714us/step - loss: 1.3712 - accuracy: 0.3389\n",
      "Epoch 4/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 1.2849 - accuracy: 0.3611\n",
      "Epoch 5/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 1.2450 - accuracy: 0.3444\n",
      "Epoch 6/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 1.2322 - accuracy: 0.3167\n",
      "Epoch 7/200\n",
      "15/15 [==============================] - 0s 823us/step - loss: 1.2222 - accuracy: 0.3333\n",
      "Epoch 8/200\n",
      "15/15 [==============================] - 0s 714us/step - loss: 1.2104 - accuracy: 0.3778\n",
      "Epoch 9/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 1.2002 - accuracy: 0.3889\n",
      "Epoch 10/200\n",
      "15/15 [==============================] - 0s 714us/step - loss: 1.1944 - accuracy: 0.3667\n",
      "Epoch 11/200\n",
      "15/15 [==============================] - 0s 643us/step - loss: 1.1939 - accuracy: 0.3833\n",
      "Epoch 12/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 1.1845 - accuracy: 0.3333\n",
      "Epoch 13/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 1.1805 - accuracy: 0.3444\n",
      "Epoch 14/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 1.1846 - accuracy: 0.3444\n",
      "Epoch 15/200\n",
      "15/15 [==============================] - 0s 883us/step - loss: 1.1705 - accuracy: 0.3722\n",
      "Epoch 16/200\n",
      "15/15 [==============================] - 0s 767us/step - loss: 1.1740 - accuracy: 0.3833\n",
      "Epoch 17/200\n",
      "15/15 [==============================] - 0s 714us/step - loss: 1.1680 - accuracy: 0.4167\n",
      "Epoch 18/200\n",
      "15/15 [==============================] - 0s 714us/step - loss: 1.1713 - accuracy: 0.3333\n",
      "Epoch 19/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 1.1588 - accuracy: 0.3556\n",
      "Epoch 20/200\n",
      "15/15 [==============================] - 0s 714us/step - loss: 1.1630 - accuracy: 0.3722\n",
      "Epoch 21/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 1.1593 - accuracy: 0.3944\n",
      "Epoch 22/200\n",
      "15/15 [==============================] - 0s 750us/step - loss: 1.1548 - accuracy: 0.3833\n",
      "Epoch 23/200\n",
      "15/15 [==============================] - 0s 714us/step - loss: 1.1475 - accuracy: 0.4056\n",
      "Epoch 24/200\n",
      "15/15 [==============================] - 0s 714us/step - loss: 1.1525 - accuracy: 0.3556\n",
      "Epoch 25/200\n",
      "15/15 [==============================] - 0s 714us/step - loss: 1.1463 - accuracy: 0.3722\n",
      "Epoch 26/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 1.1503 - accuracy: 0.3778\n",
      "Epoch 27/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 1.1341 - accuracy: 0.4222\n",
      "Epoch 28/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 1.1485 - accuracy: 0.4056\n",
      "Epoch 29/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 1.1419 - accuracy: 0.3833\n",
      "Epoch 30/200\n",
      "15/15 [==============================] - 0s 751us/step - loss: 1.1346 - accuracy: 0.4000\n",
      "Epoch 31/200\n",
      "15/15 [==============================] - 0s 857us/step - loss: 1.1385 - accuracy: 0.3667\n",
      "Epoch 32/200\n",
      "15/15 [==============================] - 0s 714us/step - loss: 1.1336 - accuracy: 0.3611\n",
      "Epoch 33/200\n",
      "15/15 [==============================] - 0s 715us/step - loss: 1.1341 - accuracy: 0.3889\n",
      "Epoch 34/200\n",
      "15/15 [==============================] - 0s 714us/step - loss: 1.1254 - accuracy: 0.3944\n",
      "Epoch 35/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 1.1229 - accuracy: 0.4222\n",
      "Epoch 36/200\n",
      "15/15 [==============================] - 0s 714us/step - loss: 1.1255 - accuracy: 0.3944\n",
      "Epoch 37/200\n",
      "15/15 [==============================] - 0s 715us/step - loss: 1.1133 - accuracy: 0.4278\n",
      "Epoch 38/200\n",
      "15/15 [==============================] - 0s 747us/step - loss: 1.1362 - accuracy: 0.3722\n",
      "Epoch 39/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 1.1509 - accuracy: 0.3556\n",
      "Epoch 40/200\n",
      "15/15 [==============================] - 0s 714us/step - loss: 1.1156 - accuracy: 0.4500\n",
      "Epoch 41/200\n",
      "15/15 [==============================] - 0s 714us/step - loss: 1.1308 - accuracy: 0.3556\n",
      "Epoch 42/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 1.1512 - accuracy: 0.3889\n",
      "Epoch 43/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 1.1250 - accuracy: 0.3778\n",
      "Epoch 44/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 1.1040 - accuracy: 0.4500\n",
      "Epoch 45/200\n",
      "15/15 [==============================] - 0s 714us/step - loss: 1.1078 - accuracy: 0.3778\n",
      "Epoch 46/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 1.1011 - accuracy: 0.4222\n",
      "Epoch 47/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 1.0885 - accuracy: 0.5111\n",
      "Epoch 48/200\n",
      "15/15 [==============================] - 0s 857us/step - loss: 1.0894 - accuracy: 0.4556\n",
      "Epoch 49/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 1.0775 - accuracy: 0.5667\n",
      "Epoch 50/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 1.0761 - accuracy: 0.4500\n",
      "Epoch 51/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 1.0708 - accuracy: 0.4056\n",
      "Epoch 52/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 1.0705 - accuracy: 0.4833\n",
      "Epoch 53/200\n",
      "15/15 [==============================] - 0s 719us/step - loss: 1.0696 - accuracy: 0.4000\n",
      "Epoch 54/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.0630 - accuracy: 0.4500\n",
      "Epoch 55/200\n",
      "15/15 [==============================] - 0s 715us/step - loss: 1.0611 - accuracy: 0.5111\n",
      "Epoch 56/200\n",
      "15/15 [==============================] - 0s 785us/step - loss: 1.0560 - accuracy: 0.4667\n",
      "Epoch 57/200\n",
      "15/15 [==============================] - 0s 715us/step - loss: 1.0426 - accuracy: 0.5278\n",
      "Epoch 58/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 1.0363 - accuracy: 0.4889\n",
      "Epoch 59/200\n",
      "15/15 [==============================] - 0s 715us/step - loss: 1.0338 - accuracy: 0.4500\n",
      "Epoch 60/200\n",
      "15/15 [==============================] - 0s 680us/step - loss: 1.0636 - accuracy: 0.4444\n",
      "Epoch 61/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 1.0194 - accuracy: 0.5111\n",
      "Epoch 62/200\n",
      "15/15 [==============================] - 0s 714us/step - loss: 1.0380 - accuracy: 0.4333\n",
      "Epoch 63/200\n",
      "15/15 [==============================] - 0s 714us/step - loss: 1.0327 - accuracy: 0.4944\n",
      "Epoch 64/200\n",
      "15/15 [==============================] - 0s 785us/step - loss: 1.0072 - accuracy: 0.4611\n",
      "Epoch 65/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 0.9954 - accuracy: 0.5111\n",
      "Epoch 66/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 1.0057 - accuracy: 0.5000\n",
      "Epoch 67/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 1.0194 - accuracy: 0.5111\n",
      "Epoch 68/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 1.0438 - accuracy: 0.4278\n",
      "Epoch 69/200\n",
      "15/15 [==============================] - 0s 929us/step - loss: 1.0376 - accuracy: 0.4444\n",
      "Epoch 70/200\n",
      "15/15 [==============================] - 0s 857us/step - loss: 1.0050 - accuracy: 0.5333\n",
      "Epoch 71/200\n",
      "15/15 [==============================] - 0s 857us/step - loss: 0.9781 - accuracy: 0.5944\n",
      "Epoch 72/200\n",
      "15/15 [==============================] - 0s 857us/step - loss: 0.9519 - accuracy: 0.6111\n",
      "Epoch 73/200\n",
      "15/15 [==============================] - 0s 857us/step - loss: 0.9374 - accuracy: 0.6278\n",
      "Epoch 74/200\n",
      "15/15 [==============================] - 0s 932us/step - loss: 0.9488 - accuracy: 0.5389\n",
      "Epoch 75/200\n",
      "15/15 [==============================] - 0s 857us/step - loss: 0.9483 - accuracy: 0.5278\n",
      "Epoch 76/200\n",
      "15/15 [==============================] - 0s 1000us/step - loss: 0.9312 - accuracy: 0.5333\n",
      "Epoch 77/200\n",
      "15/15 [==============================] - 0s 857us/step - loss: 0.9181 - accuracy: 0.5778\n",
      "Epoch 78/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 0.8796 - accuracy: 0.6833\n",
      "Epoch 79/200\n",
      "15/15 [==============================] - 0s 857us/step - loss: 0.8624 - accuracy: 0.6556\n",
      "Epoch 80/200\n",
      "15/15 [==============================] - 0s 715us/step - loss: 0.8473 - accuracy: 0.6111\n",
      "Epoch 81/200\n",
      "15/15 [==============================] - 0s 732us/step - loss: 0.8825 - accuracy: 0.6000\n",
      "Epoch 82/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 0.8769 - accuracy: 0.6278\n",
      "Epoch 83/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.8459 - accuracy: 0.6778\n",
      "Epoch 84/200\n",
      "15/15 [==============================] - 0s 787us/step - loss: 0.8076 - accuracy: 0.6778\n",
      "Epoch 85/200\n",
      "15/15 [==============================] - 0s 785us/step - loss: 0.8192 - accuracy: 0.6500\n",
      "Epoch 86/200\n",
      "15/15 [==============================] - 0s 714us/step - loss: 0.7782 - accuracy: 0.6778\n",
      "Epoch 87/200\n",
      "15/15 [==============================] - 0s 858us/step - loss: 0.8139 - accuracy: 0.5778\n",
      "Epoch 88/200\n",
      "15/15 [==============================] - 0s 806us/step - loss: 0.8019 - accuracy: 0.5889\n",
      "Epoch 89/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 0.7408 - accuracy: 0.7611\n",
      "Epoch 90/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 0.7391 - accuracy: 0.6333\n",
      "Epoch 91/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 0.7594 - accuracy: 0.6778\n",
      "Epoch 92/200\n",
      "15/15 [==============================] - 0s 714us/step - loss: 0.7202 - accuracy: 0.6944\n",
      "Epoch 93/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 0.6871 - accuracy: 0.7444\n",
      "Epoch 94/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 0.7461 - accuracy: 0.6500\n",
      "Epoch 95/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 0.7180 - accuracy: 0.6944\n",
      "Epoch 96/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 0.6646 - accuracy: 0.7778\n",
      "Epoch 97/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 0.6756 - accuracy: 0.7167\n",
      "Epoch 98/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 0.6508 - accuracy: 0.7111\n",
      "Epoch 99/200\n",
      "15/15 [==============================] - 0s 845us/step - loss: 0.6432 - accuracy: 0.7611\n",
      "Epoch 100/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 0.6684 - accuracy: 0.7667\n",
      "Epoch 101/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 0.6188 - accuracy: 0.7444\n",
      "Epoch 102/200\n",
      "15/15 [==============================] - 0s 715us/step - loss: 0.6326 - accuracy: 0.7444\n",
      "Epoch 103/200\n",
      "15/15 [==============================] - 0s 822us/step - loss: 0.6357 - accuracy: 0.7111\n",
      "Epoch 104/200\n",
      "15/15 [==============================] - 0s 857us/step - loss: 0.6005 - accuracy: 0.7944\n",
      "Epoch 105/200\n",
      "15/15 [==============================] - 0s 857us/step - loss: 0.6074 - accuracy: 0.7389\n",
      "Epoch 106/200\n",
      "15/15 [==============================] - 0s 857us/step - loss: 0.5953 - accuracy: 0.7778\n",
      "Epoch 107/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 0.5861 - accuracy: 0.7778\n",
      "Epoch 108/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 0.5635 - accuracy: 0.7778\n",
      "Epoch 109/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 0.5704 - accuracy: 0.7722\n",
      "Epoch 110/200\n",
      "15/15 [==============================] - 0s 751us/step - loss: 0.5679 - accuracy: 0.7611\n",
      "Epoch 111/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 0.5606 - accuracy: 0.7444\n",
      "Epoch 112/200\n",
      "15/15 [==============================] - 0s 714us/step - loss: 0.5518 - accuracy: 0.8333\n",
      "Epoch 113/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 0.5799 - accuracy: 0.7833\n",
      "Epoch 114/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 0.6022 - accuracy: 0.7278\n",
      "Epoch 115/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 0.5631 - accuracy: 0.7667\n",
      "Epoch 116/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 0.5394 - accuracy: 0.8222\n",
      "Epoch 117/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 0.5446 - accuracy: 0.7500\n",
      "Epoch 118/200\n",
      "15/15 [==============================] - 0s 717us/step - loss: 0.5053 - accuracy: 0.8000\n",
      "Epoch 119/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 0.5254 - accuracy: 0.7833\n",
      "Epoch 120/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 0.5641 - accuracy: 0.7389\n",
      "Epoch 121/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 0.4977 - accuracy: 0.8222\n",
      "Epoch 122/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 0.4844 - accuracy: 0.8056\n",
      "Epoch 123/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 0.5253 - accuracy: 0.7833\n",
      "Epoch 124/200\n",
      "15/15 [==============================] - 0s 715us/step - loss: 0.5496 - accuracy: 0.7167\n",
      "Epoch 125/200\n",
      "15/15 [==============================] - 0s 726us/step - loss: 0.5262 - accuracy: 0.8111\n",
      "Epoch 126/200\n",
      "15/15 [==============================] - 0s 714us/step - loss: 0.4691 - accuracy: 0.8278\n",
      "Epoch 127/200\n",
      "15/15 [==============================] - 0s 714us/step - loss: 0.4677 - accuracy: 0.8056\n",
      "Epoch 128/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 0.4654 - accuracy: 0.8111\n",
      "Epoch 129/200\n",
      "15/15 [==============================] - 0s 715us/step - loss: 0.4589 - accuracy: 0.7944\n",
      "Epoch 130/200\n",
      "15/15 [==============================] - 0s 721us/step - loss: 0.4504 - accuracy: 0.8556\n",
      "Epoch 131/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 0.5053 - accuracy: 0.7778\n",
      "Epoch 132/200\n",
      "15/15 [==============================] - 0s 715us/step - loss: 0.5253 - accuracy: 0.7500\n",
      "Epoch 133/200\n",
      "15/15 [==============================] - 0s 720us/step - loss: 0.4927 - accuracy: 0.7778\n",
      "Epoch 134/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 0.4545 - accuracy: 0.8000\n",
      "Epoch 135/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 0.4542 - accuracy: 0.8056\n",
      "Epoch 136/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 0.4417 - accuracy: 0.7944\n",
      "Epoch 137/200\n",
      "15/15 [==============================] - 0s 715us/step - loss: 0.5123 - accuracy: 0.7389\n",
      "Epoch 138/200\n",
      "15/15 [==============================] - 0s 715us/step - loss: 0.4792 - accuracy: 0.7889\n",
      "Epoch 139/200\n",
      "15/15 [==============================] - 0s 715us/step - loss: 0.5198 - accuracy: 0.7167\n",
      "Epoch 140/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.4309 - accuracy: 0.8222\n",
      "Epoch 141/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.4427 - accuracy: 0.8500\n",
      "Epoch 142/200\n",
      "15/15 [==============================] - 0s 857us/step - loss: 0.4257 - accuracy: 0.8444\n",
      "Epoch 143/200\n",
      "15/15 [==============================] - 0s 857us/step - loss: 0.4502 - accuracy: 0.8056\n",
      "Epoch 144/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 0.4202 - accuracy: 0.8667\n",
      "Epoch 145/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 0.4256 - accuracy: 0.8333\n",
      "Epoch 146/200\n",
      "15/15 [==============================] - 0s 857us/step - loss: 0.4929 - accuracy: 0.7333\n",
      "Epoch 147/200\n",
      "15/15 [==============================] - 0s 751us/step - loss: 0.3890 - accuracy: 0.8389\n",
      "Epoch 148/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 0.4028 - accuracy: 0.8333\n",
      "Epoch 149/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 0.4032 - accuracy: 0.8556\n",
      "Epoch 150/200\n",
      "15/15 [==============================] - 0s 857us/step - loss: 0.4257 - accuracy: 0.8278\n",
      "Epoch 151/200\n",
      "15/15 [==============================] - 0s 857us/step - loss: 0.4525 - accuracy: 0.7889\n",
      "Epoch 152/200\n",
      "15/15 [==============================] - 0s 857us/step - loss: 0.3968 - accuracy: 0.8611\n",
      "Epoch 153/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 0.4208 - accuracy: 0.8000\n",
      "Epoch 154/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 0.4397 - accuracy: 0.8333\n",
      "Epoch 155/200\n",
      "15/15 [==============================] - 0s 857us/step - loss: 0.4955 - accuracy: 0.7333\n",
      "Epoch 156/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 0.5088 - accuracy: 0.7722\n",
      "Epoch 157/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 0.4380 - accuracy: 0.8222\n",
      "Epoch 158/200\n",
      "15/15 [==============================] - 0s 857us/step - loss: 0.3776 - accuracy: 0.8667\n",
      "Epoch 159/200\n",
      "15/15 [==============================] - 0s 857us/step - loss: 0.4327 - accuracy: 0.7611\n",
      "Epoch 160/200\n",
      "15/15 [==============================] - 0s 714us/step - loss: 0.3676 - accuracy: 0.8778\n",
      "Epoch 161/200\n",
      "15/15 [==============================] - 0s 785us/step - loss: 0.3675 - accuracy: 0.8444\n",
      "Epoch 162/200\n",
      "15/15 [==============================] - 0s 822us/step - loss: 0.3488 - accuracy: 0.8667\n",
      "Epoch 163/200\n",
      "15/15 [==============================] - 0s 702us/step - loss: 0.3606 - accuracy: 0.8389\n",
      "Epoch 164/200\n",
      "15/15 [==============================] - 0s 928us/step - loss: 0.3491 - accuracy: 0.8667\n",
      "Epoch 165/200\n",
      "15/15 [==============================] - 0s 928us/step - loss: 0.4137 - accuracy: 0.8222\n",
      "Epoch 166/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 0.3987 - accuracy: 0.8278\n",
      "Epoch 167/200\n",
      "15/15 [==============================] - 0s 719us/step - loss: 0.3635 - accuracy: 0.8444\n",
      "Epoch 168/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 0.4725 - accuracy: 0.7778\n",
      "Epoch 169/200\n",
      "15/15 [==============================] - 0s 806us/step - loss: 0.5979 - accuracy: 0.7111\n",
      "Epoch 170/200\n",
      "15/15 [==============================] - 0s 714us/step - loss: 0.4621 - accuracy: 0.7722\n",
      "Epoch 171/200\n",
      "15/15 [==============================] - 0s 643us/step - loss: 0.3844 - accuracy: 0.8333\n",
      "Epoch 172/200\n",
      "15/15 [==============================] - 0s 714us/step - loss: 0.3624 - accuracy: 0.8611\n",
      "Epoch 173/200\n",
      "15/15 [==============================] - 0s 643us/step - loss: 0.3466 - accuracy: 0.8556\n",
      "Epoch 174/200\n",
      "15/15 [==============================] - 0s 714us/step - loss: 0.3259 - accuracy: 0.8611\n",
      "Epoch 175/200\n",
      "15/15 [==============================] - 0s 714us/step - loss: 0.3297 - accuracy: 0.8889\n",
      "Epoch 176/200\n",
      "15/15 [==============================] - 0s 715us/step - loss: 0.3353 - accuracy: 0.8667\n",
      "Epoch 177/200\n",
      "15/15 [==============================] - 0s 714us/step - loss: 0.4287 - accuracy: 0.8056\n",
      "Epoch 178/200\n",
      "15/15 [==============================] - 0s 714us/step - loss: 0.4758 - accuracy: 0.7556\n",
      "Epoch 179/200\n",
      "15/15 [==============================] - 0s 857us/step - loss: 0.5151 - accuracy: 0.7667\n",
      "Epoch 180/200\n",
      "15/15 [==============================] - 0s 767us/step - loss: 0.5162 - accuracy: 0.7667\n",
      "Epoch 181/200\n",
      "15/15 [==============================] - 0s 714us/step - loss: 0.3905 - accuracy: 0.8056\n",
      "Epoch 182/200\n",
      "15/15 [==============================] - 0s 714us/step - loss: 0.3345 - accuracy: 0.8500\n",
      "Epoch 183/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 0.3609 - accuracy: 0.8667\n",
      "Epoch 184/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 0.4034 - accuracy: 0.8389\n",
      "Epoch 185/200\n",
      "15/15 [==============================] - 0s 730us/step - loss: 0.3460 - accuracy: 0.8444\n",
      "Epoch 186/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 0.3425 - accuracy: 0.8722\n",
      "Epoch 187/200\n",
      "15/15 [==============================] - 0s 714us/step - loss: 0.3307 - accuracy: 0.8778\n",
      "Epoch 188/200\n",
      "15/15 [==============================] - 0s 715us/step - loss: 0.3632 - accuracy: 0.8111\n",
      "Epoch 189/200\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.3519 - accuracy: 0.8833\n",
      "Epoch 190/200\n",
      "15/15 [==============================] - 0s 857us/step - loss: 0.2973 - accuracy: 0.8833\n",
      "Epoch 191/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 0.3240 - accuracy: 0.8722\n",
      "Epoch 192/200\n",
      "15/15 [==============================] - 0s 750us/step - loss: 0.3282 - accuracy: 0.8444\n",
      "Epoch 193/200\n",
      "15/15 [==============================] - 0s 714us/step - loss: 0.3129 - accuracy: 0.8889\n",
      "Epoch 194/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 0.3541 - accuracy: 0.8333\n",
      "Epoch 195/200\n",
      "15/15 [==============================] - 0s 643us/step - loss: 0.3424 - accuracy: 0.8667\n",
      "Epoch 196/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 0.2920 - accuracy: 0.8722\n",
      "Epoch 197/200\n",
      "15/15 [==============================] - 0s 786us/step - loss: 0.2767 - accuracy: 0.8944\n",
      "Epoch 198/200\n",
      "15/15 [==============================] - 0s 714us/step - loss: 0.2918 - accuracy: 0.8889\n",
      "Epoch 199/200\n",
      "15/15 [==============================] - 0s 714us/step - loss: 0.3307 - accuracy: 0.8556\n",
      "Epoch 200/200\n",
      "15/15 [==============================] - 0s 714us/step - loss: 0.4195 - accuracy: 0.7833\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x19baad9b5b0>"
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "\n",
    "model1.add(Input(30, ))\n",
    "\n",
    "model1.add(Dense(30, activation='tanh'))\n",
    "model1.add(Dense(30, activation='tanh'))\n",
    "model1.add(Dense(30, activation='tanh'))\n",
    "model1.add(Dense(30, activation='tanh'))\n",
    "\n",
    "model1.add(Dense(6, activation='sigmoid'))\n",
    "\n",
    "opt1 = Adam()\n",
    "model1.compile(optimizer=opt1, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model1.fit(train_features_tensor, train_targets_tensor, epochs=200, batch_size=6)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 800us/step - loss: 0.3641 - accuracy: 0.8444\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.3640837073326111, 0.8444444537162781]"
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(train_features_tensor, train_targets_tensor)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 1ms/step - loss: 0.4534 - accuracy: 0.8000\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.45343199372291565, 0.800000011920929]"
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(test_features_tensor, test_targets_tensor)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Atempt at Automatic Hyperparameter tuning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Only integers, slices (`:`), ellipsis (`...`), tf.newaxis (`None`) and scalar tf.int32/tf.int64 tensors are valid indices, got array([ 36,  37,  38,  39,  40,  41,  42,  43,  44,  45,  46,  47,  48,\n        49,  50,  51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,\n        62,  63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,\n        75,  76,  77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n        88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100,\n       101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113,\n       114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126,\n       127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,\n       153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165,\n       166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178,\n       179])",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [15]\u001B[0m, in \u001B[0;36m<cell line: 19>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     16\u001B[0m param_grid \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdict\u001B[39m(model__neurons\u001B[38;5;241m=\u001B[39mneurons)\n\u001B[0;32m     18\u001B[0m grid \u001B[38;5;241m=\u001B[39m GridSearchCV(estimator\u001B[38;5;241m=\u001B[39mmodel, param_grid\u001B[38;5;241m=\u001B[39mparam_grid)\n\u001B[1;32m---> 19\u001B[0m \u001B[43mgrid\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_features_tensor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_targets_tensor\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:891\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[1;34m(self, X, y, groups, **fit_params)\u001B[0m\n\u001B[0;32m    885\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_results(\n\u001B[0;32m    886\u001B[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001B[0;32m    887\u001B[0m     )\n\u001B[0;32m    889\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m results\n\u001B[1;32m--> 891\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevaluate_candidates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    893\u001B[0m \u001B[38;5;66;03m# multimetric is determined here because in the case of a callable\u001B[39;00m\n\u001B[0;32m    894\u001B[0m \u001B[38;5;66;03m# self.scoring the return type is only known after calling\u001B[39;00m\n\u001B[0;32m    895\u001B[0m first_test_score \u001B[38;5;241m=\u001B[39m all_out[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_scores\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1392\u001B[0m, in \u001B[0;36mGridSearchCV._run_search\u001B[1;34m(self, evaluate_candidates)\u001B[0m\n\u001B[0;32m   1390\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_run_search\u001B[39m(\u001B[38;5;28mself\u001B[39m, evaluate_candidates):\n\u001B[0;32m   1391\u001B[0m     \u001B[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001B[39;00m\n\u001B[1;32m-> 1392\u001B[0m     \u001B[43mevaluate_candidates\u001B[49m\u001B[43m(\u001B[49m\u001B[43mParameterGrid\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparam_grid\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:838\u001B[0m, in \u001B[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001B[1;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[0;32m    830\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    831\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\n\u001B[0;32m    832\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFitting \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m folds for each of \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m candidates,\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    833\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m totalling \u001B[39m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m fits\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m    834\u001B[0m             n_splits, n_candidates, n_candidates \u001B[38;5;241m*\u001B[39m n_splits\n\u001B[0;32m    835\u001B[0m         )\n\u001B[0;32m    836\u001B[0m     )\n\u001B[1;32m--> 838\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mparallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    839\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fit_and_score\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    840\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbase_estimator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    841\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    842\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    843\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    844\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtest\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    845\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparameters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    846\u001B[0m \u001B[43m        \u001B[49m\u001B[43msplit_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_splits\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    847\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcandidate_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_candidates\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    848\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_and_score_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    849\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    850\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mproduct\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    851\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcandidate_params\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    852\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    853\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    855\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    856\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    857\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo fits were performed. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    858\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWas the CV iterator empty? \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    859\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWere there no candidates?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    860\u001B[0m     )\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:1043\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1034\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1035\u001B[0m     \u001B[38;5;66;03m# Only set self._iterating to True if at least a batch\u001B[39;00m\n\u001B[0;32m   1036\u001B[0m     \u001B[38;5;66;03m# was dispatched. In particular this covers the edge\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1040\u001B[0m     \u001B[38;5;66;03m# was very quick and its callback already dispatched all the\u001B[39;00m\n\u001B[0;32m   1041\u001B[0m     \u001B[38;5;66;03m# remaining jobs.\u001B[39;00m\n\u001B[0;32m   1042\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterating \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m-> 1043\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdispatch_one_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[0;32m   1044\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterating \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_original_iterator \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1046\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdispatch_one_batch(iterator):\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:861\u001B[0m, in \u001B[0;36mParallel.dispatch_one_batch\u001B[1;34m(self, iterator)\u001B[0m\n\u001B[0;32m    859\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m    860\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 861\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dispatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtasks\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    862\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:779\u001B[0m, in \u001B[0;36mParallel._dispatch\u001B[1;34m(self, batch)\u001B[0m\n\u001B[0;32m    777\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[0;32m    778\u001B[0m     job_idx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs)\n\u001B[1;32m--> 779\u001B[0m     job \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_backend\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_async\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    780\u001B[0m     \u001B[38;5;66;03m# A job can complete so quickly than its callback is\u001B[39;00m\n\u001B[0;32m    781\u001B[0m     \u001B[38;5;66;03m# called before we get here, causing self._jobs to\u001B[39;00m\n\u001B[0;32m    782\u001B[0m     \u001B[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001B[39;00m\n\u001B[0;32m    783\u001B[0m     \u001B[38;5;66;03m# used (rather than .append) in the following line\u001B[39;00m\n\u001B[0;32m    784\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs\u001B[38;5;241m.\u001B[39minsert(job_idx, job)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001B[0m, in \u001B[0;36mSequentialBackend.apply_async\u001B[1;34m(self, func, callback)\u001B[0m\n\u001B[0;32m    206\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply_async\u001B[39m(\u001B[38;5;28mself\u001B[39m, func, callback\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m    207\u001B[0m     \u001B[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001B[39;00m\n\u001B[1;32m--> 208\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mImmediateResult\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    209\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m callback:\n\u001B[0;32m    210\u001B[0m         callback(result)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001B[0m, in \u001B[0;36mImmediateResult.__init__\u001B[1;34m(self, batch)\u001B[0m\n\u001B[0;32m    569\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, batch):\n\u001B[0;32m    570\u001B[0m     \u001B[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001B[39;00m\n\u001B[0;32m    571\u001B[0m     \u001B[38;5;66;03m# arguments in memory\u001B[39;00m\n\u001B[1;32m--> 572\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresults \u001B[38;5;241m=\u001B[39m \u001B[43mbatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:262\u001B[0m, in \u001B[0;36mBatchedCalls.__call__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    258\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    259\u001B[0m     \u001B[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001B[39;00m\n\u001B[0;32m    260\u001B[0m     \u001B[38;5;66;03m# change the default number of processes to -1\u001B[39;00m\n\u001B[0;32m    261\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m parallel_backend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_jobs):\n\u001B[1;32m--> 262\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    263\u001B[0m                 \u001B[38;5;28;01mfor\u001B[39;00m func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems]\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:262\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    258\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    259\u001B[0m     \u001B[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001B[39;00m\n\u001B[0;32m    260\u001B[0m     \u001B[38;5;66;03m# change the default number of processes to -1\u001B[39;00m\n\u001B[0;32m    261\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m parallel_backend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_jobs):\n\u001B[1;32m--> 262\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    263\u001B[0m                 \u001B[38;5;28;01mfor\u001B[39;00m func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems]\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py:216\u001B[0m, in \u001B[0;36m_FuncWrapper.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    214\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    215\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig):\n\u001B[1;32m--> 216\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:672\u001B[0m, in \u001B[0;36m_fit_and_score\u001B[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001B[0m\n\u001B[0;32m    668\u001B[0m     estimator \u001B[38;5;241m=\u001B[39m estimator\u001B[38;5;241m.\u001B[39mset_params(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcloned_parameters)\n\u001B[0;32m    670\u001B[0m start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m--> 672\u001B[0m X_train, y_train \u001B[38;5;241m=\u001B[39m \u001B[43m_safe_split\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    673\u001B[0m X_test, y_test \u001B[38;5;241m=\u001B[39m _safe_split(estimator, X, y, test, train)\n\u001B[0;32m    675\u001B[0m result \u001B[38;5;241m=\u001B[39m {}\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py:288\u001B[0m, in \u001B[0;36m_safe_split\u001B[1;34m(estimator, X, y, indices, train_indices)\u001B[0m\n\u001B[0;32m    286\u001B[0m         X_subset \u001B[38;5;241m=\u001B[39m X[np\u001B[38;5;241m.\u001B[39mix_(indices, train_indices)]\n\u001B[0;32m    287\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 288\u001B[0m     X_subset \u001B[38;5;241m=\u001B[39m \u001B[43m_safe_indexing\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindices\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    290\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m y \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    291\u001B[0m     y_subset \u001B[38;5;241m=\u001B[39m _safe_indexing(y, indices)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py:378\u001B[0m, in \u001B[0;36m_safe_indexing\u001B[1;34m(X, indices, axis)\u001B[0m\n\u001B[0;32m    376\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _pandas_indexing(X, indices, indices_dtype, axis\u001B[38;5;241m=\u001B[39maxis)\n\u001B[0;32m    377\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(X, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mshape\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m--> 378\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_array_indexing\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindices\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindices_dtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    379\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    380\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _list_indexing(X, indices, indices_dtype)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py:202\u001B[0m, in \u001B[0;36m_array_indexing\u001B[1;34m(array, key, key_dtype, axis)\u001B[0m\n\u001B[0;32m    200\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(key, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[0;32m    201\u001B[0m     key \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(key)\n\u001B[1;32m--> 202\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43marray\u001B[49m\u001B[43m[\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mif\u001B[39;00m axis \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m array[:, key]\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m--> 153\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[0;32m    154\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    155\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:906\u001B[0m, in \u001B[0;36m_check_index\u001B[1;34m(idx)\u001B[0m\n\u001B[0;32m    901\u001B[0m dtype \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(idx, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdtype\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m    902\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (dtype \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m dtypes\u001B[38;5;241m.\u001B[39mas_dtype(dtype) \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m _SUPPORTED_SLICE_DTYPES \u001B[38;5;129;01mor\u001B[39;00m\n\u001B[0;32m    903\u001B[0m     idx\u001B[38;5;241m.\u001B[39mshape \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(idx\u001B[38;5;241m.\u001B[39mshape) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m):\n\u001B[0;32m    904\u001B[0m   \u001B[38;5;66;03m# TODO(slebedev): IndexError seems more appropriate here, but it\u001B[39;00m\n\u001B[0;32m    905\u001B[0m   \u001B[38;5;66;03m# will break `_slice_helper` contract.\u001B[39;00m\n\u001B[1;32m--> 906\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(_SLICE_TYPE_ERROR \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m, got \u001B[39m\u001B[38;5;132;01m{!r}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(idx))\n",
      "\u001B[1;31mTypeError\u001B[0m: Only integers, slices (`:`), ellipsis (`...`), tf.newaxis (`None`) and scalar tf.int32/tf.int64 tensors are valid indices, got array([ 36,  37,  38,  39,  40,  41,  42,  43,  44,  45,  46,  47,  48,\n        49,  50,  51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,\n        62,  63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,\n        75,  76,  77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n        88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100,\n       101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113,\n       114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126,\n       127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,\n       153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165,\n       166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178,\n       179])"
     ]
    }
   ],
   "source": [
    "def create_model1(neurons):\n",
    "    #  learning_rate, layer1_neurons, layer2_neurons, layer3_neurons, layer4_neurons\n",
    "    model = Sequential()\n",
    "    model.add(input(13, ))\n",
    "    model.add(Dense(neurons, activation='relu'))\n",
    "    model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "    opt1 = Adam(learning_rate=0.01)\n",
    "    model.compile(optimizer=opt1, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(model=create_model1, epochs=200, batch_size=10, neurons=13)\n",
    "\n",
    "neurons = [1, 5, 10, 15, 20, 25, 30]\n",
    "param_grid = dict(model__neurons=neurons)\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid)\n",
    "grid.fit(train_features_tensor, train_targets_tensor)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# NN Architecture 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "18/18 [==============================] - 0s 824us/step - loss: 1.7896 - accuracy: 0.1833\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 706us/step - loss: 1.6487 - accuracy: 0.2611\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 765us/step - loss: 1.4737 - accuracy: 0.3278\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 778us/step - loss: 1.3683 - accuracy: 0.2833\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 765us/step - loss: 1.2939 - accuracy: 0.3444\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 765us/step - loss: 1.2630 - accuracy: 0.3778\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 765us/step - loss: 1.2680 - accuracy: 0.3611\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 706us/step - loss: 1.2442 - accuracy: 0.3389\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 706us/step - loss: 1.2366 - accuracy: 0.3833\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 728us/step - loss: 1.2480 - accuracy: 0.2778\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 765us/step - loss: 1.2211 - accuracy: 0.3667\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 736us/step - loss: 1.2409 - accuracy: 0.2889\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.2203 - accuracy: 0.3833\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.2354 - accuracy: 0.2889\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.2311 - accuracy: 0.3667\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1979 - accuracy: 0.3722\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.2152 - accuracy: 0.3667\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.2197 - accuracy: 0.2889\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.2278 - accuracy: 0.3333\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.2050 - accuracy: 0.3056\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.2252 - accuracy: 0.3333\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1770 - accuracy: 0.4111\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.2065 - accuracy: 0.3389\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.2070 - accuracy: 0.3667\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.2012 - accuracy: 0.3611\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1606 - accuracy: 0.4167\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.1936 - accuracy: 0.3278\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.2214 - accuracy: 0.3333\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1593 - accuracy: 0.3944\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.1404 - accuracy: 0.4111\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.1871 - accuracy: 0.3444\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1892 - accuracy: 0.3889\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1581 - accuracy: 0.3889\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1399 - accuracy: 0.4333\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1568 - accuracy: 0.3833\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.1575 - accuracy: 0.3778\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1782 - accuracy: 0.3278\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1658 - accuracy: 0.3944\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1518 - accuracy: 0.3667\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1624 - accuracy: 0.3611\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1555 - accuracy: 0.4056\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1226 - accuracy: 0.3722\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1974 - accuracy: 0.3944\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1723 - accuracy: 0.4000\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1810 - accuracy: 0.3556\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.1690 - accuracy: 0.3667\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1547 - accuracy: 0.3444\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1462 - accuracy: 0.3611\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.1341 - accuracy: 0.4111\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.1503 - accuracy: 0.3500\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.1718 - accuracy: 0.3889\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.1392 - accuracy: 0.4556\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1421 - accuracy: 0.3667\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.1345 - accuracy: 0.3500\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1415 - accuracy: 0.3722\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.1354 - accuracy: 0.3722\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.1304 - accuracy: 0.3500\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.1535 - accuracy: 0.3500\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1421 - accuracy: 0.4389\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1427 - accuracy: 0.3556\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.1526 - accuracy: 0.4222\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1310 - accuracy: 0.3611\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1150 - accuracy: 0.4222\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.1316 - accuracy: 0.4167\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1256 - accuracy: 0.3944\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1150 - accuracy: 0.3944\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1310 - accuracy: 0.4000\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.1109 - accuracy: 0.3611\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1084 - accuracy: 0.3889\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1027 - accuracy: 0.4111\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1190 - accuracy: 0.3889\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0798 - accuracy: 0.4222\n",
      "Epoch 73/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0820 - accuracy: 0.4500\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0804 - accuracy: 0.4278\n",
      "Epoch 75/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.0581 - accuracy: 0.4833\n",
      "Epoch 76/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.0954 - accuracy: 0.4667\n",
      "Epoch 77/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.0936 - accuracy: 0.4389\n",
      "Epoch 78/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.0929 - accuracy: 0.5000\n",
      "Epoch 79/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0473 - accuracy: 0.4500\n",
      "Epoch 80/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0637 - accuracy: 0.4278\n",
      "Epoch 81/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.0442 - accuracy: 0.4389\n",
      "Epoch 82/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.0765 - accuracy: 0.4222\n",
      "Epoch 83/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.0620 - accuracy: 0.5000\n",
      "Epoch 84/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0490 - accuracy: 0.4889\n",
      "Epoch 85/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0477 - accuracy: 0.4611\n",
      "Epoch 86/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0454 - accuracy: 0.4556\n",
      "Epoch 87/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.0123 - accuracy: 0.5111\n",
      "Epoch 88/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9998 - accuracy: 0.5000\n",
      "Epoch 89/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.0012 - accuracy: 0.5222\n",
      "Epoch 90/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.0092 - accuracy: 0.4278\n",
      "Epoch 91/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9900 - accuracy: 0.5056\n",
      "Epoch 92/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.9480 - accuracy: 0.5889\n",
      "Epoch 93/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.9944 - accuracy: 0.5167\n",
      "Epoch 94/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9540 - accuracy: 0.5389\n",
      "Epoch 95/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9254 - accuracy: 0.6111\n",
      "Epoch 96/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9417 - accuracy: 0.5389\n",
      "Epoch 97/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.9363 - accuracy: 0.5389\n",
      "Epoch 98/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.9012 - accuracy: 0.5833\n",
      "Epoch 99/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8568 - accuracy: 0.6000\n",
      "Epoch 100/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.8648 - accuracy: 0.6056\n",
      "Epoch 101/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.9000 - accuracy: 0.5611\n",
      "Epoch 102/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8714 - accuracy: 0.5444\n",
      "Epoch 103/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.8448 - accuracy: 0.5944\n",
      "Epoch 104/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7804 - accuracy: 0.6500\n",
      "Epoch 105/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7954 - accuracy: 0.5833\n",
      "Epoch 106/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7811 - accuracy: 0.6667\n",
      "Epoch 107/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.7943 - accuracy: 0.5722\n",
      "Epoch 108/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8027 - accuracy: 0.6222\n",
      "Epoch 109/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.7560 - accuracy: 0.6722\n",
      "Epoch 110/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.7601 - accuracy: 0.6278\n",
      "Epoch 111/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7512 - accuracy: 0.6222\n",
      "Epoch 112/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.7435 - accuracy: 0.6389\n",
      "Epoch 113/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7387 - accuracy: 0.6222\n",
      "Epoch 114/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.7395 - accuracy: 0.6333\n",
      "Epoch 115/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7840 - accuracy: 0.6111\n",
      "Epoch 116/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7316 - accuracy: 0.6556\n",
      "Epoch 117/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6761 - accuracy: 0.7333\n",
      "Epoch 118/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6745 - accuracy: 0.7000\n",
      "Epoch 119/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6817 - accuracy: 0.6778\n",
      "Epoch 120/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6735 - accuracy: 0.6889\n",
      "Epoch 121/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6782 - accuracy: 0.7222\n",
      "Epoch 122/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6773 - accuracy: 0.6833\n",
      "Epoch 123/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6548 - accuracy: 0.7111\n",
      "Epoch 124/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6579 - accuracy: 0.6667\n",
      "Epoch 125/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6549 - accuracy: 0.7056\n",
      "Epoch 126/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6634 - accuracy: 0.6889\n",
      "Epoch 127/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6760 - accuracy: 0.6944\n",
      "Epoch 128/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.6500\n",
      "Epoch 129/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6648 - accuracy: 0.6444\n",
      "Epoch 130/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6316 - accuracy: 0.7111\n",
      "Epoch 131/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6309 - accuracy: 0.7500\n",
      "Epoch 132/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6202 - accuracy: 0.7222\n",
      "Epoch 133/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6569 - accuracy: 0.7056\n",
      "Epoch 134/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6922 - accuracy: 0.6111\n",
      "Epoch 135/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6664 - accuracy: 0.6389\n",
      "Epoch 136/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6360 - accuracy: 0.6778\n",
      "Epoch 137/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6115 - accuracy: 0.7111\n",
      "Epoch 138/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6349 - accuracy: 0.7167\n",
      "Epoch 139/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5782 - accuracy: 0.7500\n",
      "Epoch 140/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5884 - accuracy: 0.7444\n",
      "Epoch 141/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6236 - accuracy: 0.6944\n",
      "Epoch 142/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6574 - accuracy: 0.6389\n",
      "Epoch 143/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6680 - accuracy: 0.6667\n",
      "Epoch 144/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5966 - accuracy: 0.7111\n",
      "Epoch 145/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5859 - accuracy: 0.7611\n",
      "Epoch 146/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6115 - accuracy: 0.6944\n",
      "Epoch 147/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6459 - accuracy: 0.6722\n",
      "Epoch 148/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6338 - accuracy: 0.6722\n",
      "Epoch 149/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5776 - accuracy: 0.7333\n",
      "Epoch 150/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5517 - accuracy: 0.7389\n",
      "Epoch 151/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6190 - accuracy: 0.7056\n",
      "Epoch 152/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5959 - accuracy: 0.6889\n",
      "Epoch 153/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6037 - accuracy: 0.7056\n",
      "Epoch 154/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5962 - accuracy: 0.7167\n",
      "Epoch 155/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6667\n",
      "Epoch 156/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5712 - accuracy: 0.7556\n",
      "Epoch 157/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5701 - accuracy: 0.7222\n",
      "Epoch 158/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6018 - accuracy: 0.7222\n",
      "Epoch 159/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5745 - accuracy: 0.7500\n",
      "Epoch 160/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5762 - accuracy: 0.7222\n",
      "Epoch 161/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5611 - accuracy: 0.7444\n",
      "Epoch 162/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5344 - accuracy: 0.7778\n",
      "Epoch 163/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5491 - accuracy: 0.7556\n",
      "Epoch 164/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5429 - accuracy: 0.7556\n",
      "Epoch 165/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5499 - accuracy: 0.7500\n",
      "Epoch 166/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5815 - accuracy: 0.7167\n",
      "Epoch 167/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5628 - accuracy: 0.7056\n",
      "Epoch 168/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5397 - accuracy: 0.7444\n",
      "Epoch 169/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5446 - accuracy: 0.7667\n",
      "Epoch 170/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5228 - accuracy: 0.7778\n",
      "Epoch 171/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5564 - accuracy: 0.7278\n",
      "Epoch 172/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5721 - accuracy: 0.7500\n",
      "Epoch 173/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5307 - accuracy: 0.7444\n",
      "Epoch 174/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5531 - accuracy: 0.7333\n",
      "Epoch 175/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5204 - accuracy: 0.7778\n",
      "Epoch 176/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5445 - accuracy: 0.7278\n",
      "Epoch 177/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5274 - accuracy: 0.7389\n",
      "Epoch 178/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5292 - accuracy: 0.7667\n",
      "Epoch 179/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5452 - accuracy: 0.7222\n",
      "Epoch 180/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5150 - accuracy: 0.7611\n",
      "Epoch 181/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5522 - accuracy: 0.7222\n",
      "Epoch 182/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5827 - accuracy: 0.7056\n",
      "Epoch 183/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5611 - accuracy: 0.7333\n",
      "Epoch 184/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5307 - accuracy: 0.7667\n",
      "Epoch 185/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5265 - accuracy: 0.7444\n",
      "Epoch 186/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5131 - accuracy: 0.7944\n",
      "Epoch 187/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5624 - accuracy: 0.7167\n",
      "Epoch 188/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5664 - accuracy: 0.7167\n",
      "Epoch 189/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5005 - accuracy: 0.7778\n",
      "Epoch 190/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4844 - accuracy: 0.7833\n",
      "Epoch 191/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4736 - accuracy: 0.8000\n",
      "Epoch 192/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4905 - accuracy: 0.7833\n",
      "Epoch 193/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4974 - accuracy: 0.7722\n",
      "Epoch 194/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4726 - accuracy: 0.8333\n",
      "Epoch 195/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4959 - accuracy: 0.7833\n",
      "Epoch 196/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4904 - accuracy: 0.7833\n",
      "Epoch 197/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5497 - accuracy: 0.7389\n",
      "Epoch 198/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5150 - accuracy: 0.7667\n",
      "Epoch 199/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5086 - accuracy: 0.7778\n",
      "Epoch 200/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4931 - accuracy: 0.7722\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x19bc6ffd430>"
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "\n",
    "model2.add(Input(30))\n",
    "\n",
    "model2.add(Dense(30, activation='tanh'))\n",
    "model2.add(Dropout(0.2))\n",
    "\n",
    "model2.add(Dense(30, activation='tanh'))\n",
    "model2.add(Dropout(0.2))\n",
    "\n",
    "model2.add(Dense(30, activation='tanh'))\n",
    "model2.add(Dropout(0.2))\n",
    "\n",
    "model2.add(Dense(30, activation='tanh'))\n",
    "model2.add(Dense(6, activation='sigmoid'))\n",
    "\n",
    "opt1 = Adam()\n",
    "model2.compile(optimizer=opt1, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model2.fit(train_features_tensor, train_targets_tensor, epochs=200, batch_size=10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 1ms/step - loss: 0.3682 - accuracy: 0.8833\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.36816543340682983, 0.8833333253860474]"
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(train_features_tensor, train_targets_tensor)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4214 - accuracy: 0.8500\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.4213514029979706, 0.8500000238418579]"
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(test_features_tensor, test_targets_tensor)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Manuel Hyperparameter tuning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "30/30 [==============================] - 1s 3ms/step - loss: 1.6551 - accuracy: 0.2667\n",
      "Epoch 2/300\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.4000 - accuracy: 0.2667\n",
      "Epoch 3/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.2593 - accuracy: 0.3333\n",
      "Epoch 4/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.2446 - accuracy: 0.3278\n",
      "Epoch 5/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.2533 - accuracy: 0.3056\n",
      "Epoch 6/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.2489 - accuracy: 0.3056\n",
      "Epoch 7/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 1.2222 - accuracy: 0.3722\n",
      "Epoch 8/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.2199 - accuracy: 0.3444\n",
      "Epoch 9/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 1.2033 - accuracy: 0.3778\n",
      "Epoch 10/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.2155 - accuracy: 0.3611\n",
      "Epoch 11/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 1.1940 - accuracy: 0.4222\n",
      "Epoch 12/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.2297 - accuracy: 0.3222\n",
      "Epoch 13/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.1991 - accuracy: 0.3278\n",
      "Epoch 14/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 1.1853 - accuracy: 0.3222\n",
      "Epoch 15/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 1.1878 - accuracy: 0.3222\n",
      "Epoch 16/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 1.1813 - accuracy: 0.3000\n",
      "Epoch 17/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.1725 - accuracy: 0.3444\n",
      "Epoch 18/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 1.1535 - accuracy: 0.4111\n",
      "Epoch 19/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 1.2000 - accuracy: 0.3278\n",
      "Epoch 20/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.1924 - accuracy: 0.3222\n",
      "Epoch 21/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.2062 - accuracy: 0.3056\n",
      "Epoch 22/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.1817 - accuracy: 0.3500\n",
      "Epoch 23/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.1601 - accuracy: 0.4000\n",
      "Epoch 24/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.1638 - accuracy: 0.4278\n",
      "Epoch 25/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.1589 - accuracy: 0.3556\n",
      "Epoch 26/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.1440 - accuracy: 0.4667\n",
      "Epoch 27/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.1598 - accuracy: 0.3944\n",
      "Epoch 28/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 1.1774 - accuracy: 0.3389\n",
      "Epoch 29/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.1691 - accuracy: 0.3667\n",
      "Epoch 30/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.1773 - accuracy: 0.3778\n",
      "Epoch 31/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.1514 - accuracy: 0.3333\n",
      "Epoch 32/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 1.1516 - accuracy: 0.3611\n",
      "Epoch 33/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.1641 - accuracy: 0.3500\n",
      "Epoch 34/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.1548 - accuracy: 0.3556\n",
      "Epoch 35/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.1967 - accuracy: 0.3833\n",
      "Epoch 36/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.1660 - accuracy: 0.3778\n",
      "Epoch 37/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.1383 - accuracy: 0.3500\n",
      "Epoch 38/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.1520 - accuracy: 0.3667\n",
      "Epoch 39/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.1351 - accuracy: 0.4167\n",
      "Epoch 40/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.1432 - accuracy: 0.3944\n",
      "Epoch 41/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 1.1335 - accuracy: 0.3556\n",
      "Epoch 42/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 1.1362 - accuracy: 0.3944\n",
      "Epoch 43/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 1.1448 - accuracy: 0.3389\n",
      "Epoch 44/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 1.1214 - accuracy: 0.4500\n",
      "Epoch 45/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.1196 - accuracy: 0.4000\n",
      "Epoch 46/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 1.1150 - accuracy: 0.4389\n",
      "Epoch 47/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.1056 - accuracy: 0.3833\n",
      "Epoch 48/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 1.1182 - accuracy: 0.3944\n",
      "Epoch 49/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 1.1242 - accuracy: 0.4444\n",
      "Epoch 50/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 1.1015 - accuracy: 0.4500\n",
      "Epoch 51/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 1.0830 - accuracy: 0.4000\n",
      "Epoch 52/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 1.0868 - accuracy: 0.4778\n",
      "Epoch 53/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 1.0599 - accuracy: 0.4667\n",
      "Epoch 54/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 1.0601 - accuracy: 0.4611\n",
      "Epoch 55/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.0473 - accuracy: 0.4667\n",
      "Epoch 56/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 1.0596 - accuracy: 0.4556\n",
      "Epoch 57/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.9972 - accuracy: 0.5167\n",
      "Epoch 58/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 1.0022 - accuracy: 0.5222\n",
      "Epoch 59/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.0146 - accuracy: 0.5389\n",
      "Epoch 60/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 1.0087 - accuracy: 0.5000\n",
      "Epoch 61/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.9902 - accuracy: 0.4667\n",
      "Epoch 62/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.9378 - accuracy: 0.6111\n",
      "Epoch 63/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.9596 - accuracy: 0.5056\n",
      "Epoch 64/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.9019 - accuracy: 0.6111\n",
      "Epoch 65/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.8805 - accuracy: 0.6000\n",
      "Epoch 66/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.8831 - accuracy: 0.5611\n",
      "Epoch 67/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.8616 - accuracy: 0.5556\n",
      "Epoch 68/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.8060 - accuracy: 0.6444\n",
      "Epoch 69/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.8862 - accuracy: 0.5333\n",
      "Epoch 70/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.8022 - accuracy: 0.6500\n",
      "Epoch 71/300\n",
      "30/30 [==============================] - 0s 1000us/step - loss: 0.7776 - accuracy: 0.6000\n",
      "Epoch 72/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.7954 - accuracy: 0.6222\n",
      "Epoch 73/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.7963 - accuracy: 0.5667\n",
      "Epoch 74/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.7738 - accuracy: 0.6222\n",
      "Epoch 75/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.7304 - accuracy: 0.6444\n",
      "Epoch 76/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.7163 - accuracy: 0.6944\n",
      "Epoch 77/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.7457 - accuracy: 0.6833\n",
      "Epoch 78/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.7252 - accuracy: 0.6556\n",
      "Epoch 79/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.7118 - accuracy: 0.6556\n",
      "Epoch 80/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.7000\n",
      "Epoch 81/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.7072 - accuracy: 0.6778\n",
      "Epoch 82/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.7379 - accuracy: 0.6278\n",
      "Epoch 83/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6767 - accuracy: 0.6944\n",
      "Epoch 84/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.7167\n",
      "Epoch 85/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.7123 - accuracy: 0.6167\n",
      "Epoch 86/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.8115 - accuracy: 0.5667\n",
      "Epoch 87/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.6667\n",
      "Epoch 88/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6853 - accuracy: 0.6333\n",
      "Epoch 89/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6240 - accuracy: 0.7389\n",
      "Epoch 90/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6235 - accuracy: 0.7333\n",
      "Epoch 91/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6301 - accuracy: 0.6778\n",
      "Epoch 92/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6782 - accuracy: 0.6333\n",
      "Epoch 93/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6578 - accuracy: 0.6444\n",
      "Epoch 94/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6240 - accuracy: 0.6833\n",
      "Epoch 95/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6079 - accuracy: 0.7556\n",
      "Epoch 96/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6099 - accuracy: 0.7333\n",
      "Epoch 97/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6053 - accuracy: 0.7167\n",
      "Epoch 98/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6630 - accuracy: 0.7111\n",
      "Epoch 99/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.5825 - accuracy: 0.7111\n",
      "Epoch 100/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6277 - accuracy: 0.6833\n",
      "Epoch 101/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6491 - accuracy: 0.6889\n",
      "Epoch 102/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5940 - accuracy: 0.7278\n",
      "Epoch 103/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6254 - accuracy: 0.7167\n",
      "Epoch 104/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.5771 - accuracy: 0.7222\n",
      "Epoch 105/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6201 - accuracy: 0.7389\n",
      "Epoch 106/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.5919 - accuracy: 0.7222\n",
      "Epoch 107/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.5967 - accuracy: 0.7056\n",
      "Epoch 108/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5771 - accuracy: 0.7389\n",
      "Epoch 109/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.5744 - accuracy: 0.7556\n",
      "Epoch 110/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.5489 - accuracy: 0.7778\n",
      "Epoch 111/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.5275 - accuracy: 0.8000\n",
      "Epoch 112/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.5929 - accuracy: 0.7111\n",
      "Epoch 113/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5667 - accuracy: 0.7667\n",
      "Epoch 114/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6170 - accuracy: 0.7111\n",
      "Epoch 115/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6275 - accuracy: 0.7222\n",
      "Epoch 116/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5269 - accuracy: 0.7944\n",
      "Epoch 117/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5818 - accuracy: 0.7667\n",
      "Epoch 118/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5430 - accuracy: 0.7611\n",
      "Epoch 119/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5232 - accuracy: 0.7778\n",
      "Epoch 120/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.5505 - accuracy: 0.7611\n",
      "Epoch 121/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.5883 - accuracy: 0.7056\n",
      "Epoch 122/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5727 - accuracy: 0.7500\n",
      "Epoch 123/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.5899 - accuracy: 0.7667\n",
      "Epoch 124/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.4949 - accuracy: 0.7778\n",
      "Epoch 125/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5225 - accuracy: 0.7389\n",
      "Epoch 126/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4895 - accuracy: 0.8111\n",
      "Epoch 127/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5562 - accuracy: 0.7222\n",
      "Epoch 128/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6712 - accuracy: 0.6667\n",
      "Epoch 129/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.4559 - accuracy: 0.8222\n",
      "Epoch 130/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.5411 - accuracy: 0.7500\n",
      "Epoch 131/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.5051 - accuracy: 0.7778\n",
      "Epoch 132/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.4549 - accuracy: 0.8111\n",
      "Epoch 133/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.4609 - accuracy: 0.8056\n",
      "Epoch 134/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.8056\n",
      "Epoch 135/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4455 - accuracy: 0.8111\n",
      "Epoch 136/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.4366 - accuracy: 0.8111\n",
      "Epoch 137/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4776 - accuracy: 0.7611\n",
      "Epoch 138/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.4511 - accuracy: 0.8167\n",
      "Epoch 139/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.4640 - accuracy: 0.8111\n",
      "Epoch 140/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.4420 - accuracy: 0.8000\n",
      "Epoch 141/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4975 - accuracy: 0.7944\n",
      "Epoch 142/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.4725 - accuracy: 0.7833\n",
      "Epoch 143/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5005 - accuracy: 0.7556\n",
      "Epoch 144/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.4801 - accuracy: 0.7944\n",
      "Epoch 145/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.8000\n",
      "Epoch 146/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.8167\n",
      "Epoch 147/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.8389\n",
      "Epoch 148/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5412 - accuracy: 0.7722\n",
      "Epoch 149/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3909 - accuracy: 0.8500\n",
      "Epoch 150/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.4377 - accuracy: 0.8167\n",
      "Epoch 151/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.5161 - accuracy: 0.7500\n",
      "Epoch 152/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.4718 - accuracy: 0.7778\n",
      "Epoch 153/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3794 - accuracy: 0.8222\n",
      "Epoch 154/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3910 - accuracy: 0.8444\n",
      "Epoch 155/300\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5128 - accuracy: 0.7611\n",
      "Epoch 156/300\n",
      "30/30 [==============================] - 0s 724us/step - loss: 0.5390 - accuracy: 0.7889\n",
      "Epoch 157/300\n",
      "30/30 [==============================] - 0s 759us/step - loss: 0.4168 - accuracy: 0.8500\n",
      "Epoch 158/300\n",
      "30/30 [==============================] - 0s 800us/step - loss: 0.4289 - accuracy: 0.8222\n",
      "Epoch 159/300\n",
      "30/30 [==============================] - 0s 759us/step - loss: 0.3927 - accuracy: 0.8333\n",
      "Epoch 160/300\n",
      "30/30 [==============================] - 0s 793us/step - loss: 0.5584 - accuracy: 0.7500\n",
      "Epoch 161/300\n",
      "30/30 [==============================] - 0s 759us/step - loss: 0.4012 - accuracy: 0.8111\n",
      "Epoch 162/300\n",
      "30/30 [==============================] - 0s 762us/step - loss: 0.4028 - accuracy: 0.8056\n",
      "Epoch 163/300\n",
      "30/30 [==============================] - 0s 793us/step - loss: 0.3713 - accuracy: 0.8611\n",
      "Epoch 164/300\n",
      "30/30 [==============================] - 0s 759us/step - loss: 0.4184 - accuracy: 0.7889\n",
      "Epoch 165/300\n",
      "30/30 [==============================] - 0s 793us/step - loss: 0.5319 - accuracy: 0.7500\n",
      "Epoch 166/300\n",
      "30/30 [==============================] - 0s 759us/step - loss: 0.4148 - accuracy: 0.8167\n",
      "Epoch 167/300\n",
      "30/30 [==============================] - 0s 759us/step - loss: 0.4267 - accuracy: 0.8278\n",
      "Epoch 168/300\n",
      "30/30 [==============================] - 0s 793us/step - loss: 0.4179 - accuracy: 0.8222\n",
      "Epoch 169/300\n",
      "30/30 [==============================] - 0s 759us/step - loss: 0.3870 - accuracy: 0.8278\n",
      "Epoch 170/300\n",
      "30/30 [==============================] - 0s 737us/step - loss: 0.3290 - accuracy: 0.8833\n",
      "Epoch 171/300\n",
      "30/30 [==============================] - 0s 759us/step - loss: 0.3666 - accuracy: 0.8333\n",
      "Epoch 172/300\n",
      "30/30 [==============================] - 0s 759us/step - loss: 0.3624 - accuracy: 0.8389\n",
      "Epoch 173/300\n",
      "30/30 [==============================] - 0s 759us/step - loss: 0.3624 - accuracy: 0.8444\n",
      "Epoch 174/300\n",
      "30/30 [==============================] - 0s 777us/step - loss: 0.3946 - accuracy: 0.8389\n",
      "Epoch 175/300\n",
      "30/30 [==============================] - 0s 828us/step - loss: 0.3555 - accuracy: 0.8444\n",
      "Epoch 176/300\n",
      "30/30 [==============================] - 0s 759us/step - loss: 0.4073 - accuracy: 0.8111\n",
      "Epoch 177/300\n",
      "30/30 [==============================] - 0s 793us/step - loss: 0.4068 - accuracy: 0.8389\n",
      "Epoch 178/300\n",
      "30/30 [==============================] - 0s 769us/step - loss: 0.4051 - accuracy: 0.8333\n",
      "Epoch 179/300\n",
      "30/30 [==============================] - 0s 759us/step - loss: 0.3621 - accuracy: 0.8333\n",
      "Epoch 180/300\n",
      "30/30 [==============================] - 0s 793us/step - loss: 0.3715 - accuracy: 0.8333\n",
      "Epoch 181/300\n",
      "30/30 [==============================] - 0s 759us/step - loss: 0.3608 - accuracy: 0.8556\n",
      "Epoch 182/300\n",
      "30/30 [==============================] - 0s 767us/step - loss: 0.4668 - accuracy: 0.8000\n",
      "Epoch 183/300\n",
      "30/30 [==============================] - 0s 724us/step - loss: 0.4693 - accuracy: 0.8278\n",
      "Epoch 184/300\n",
      "30/30 [==============================] - 0s 759us/step - loss: 0.3841 - accuracy: 0.8389\n",
      "Epoch 185/300\n",
      "30/30 [==============================] - 0s 793us/step - loss: 0.3927 - accuracy: 0.8333\n",
      "Epoch 186/300\n",
      "30/30 [==============================] - 0s 727us/step - loss: 0.3500 - accuracy: 0.8389\n",
      "Epoch 187/300\n",
      "30/30 [==============================] - 0s 959us/step - loss: 0.3474 - accuracy: 0.8611\n",
      "Epoch 188/300\n",
      "30/30 [==============================] - 0s 793us/step - loss: 0.3591 - accuracy: 0.8500\n",
      "Epoch 189/300\n",
      "30/30 [==============================] - 0s 758us/step - loss: 0.4016 - accuracy: 0.8222\n",
      "Epoch 190/300\n",
      "30/30 [==============================] - 0s 760us/step - loss: 0.3198 - accuracy: 0.8833\n",
      "Epoch 191/300\n",
      "30/30 [==============================] - 0s 759us/step - loss: 0.3091 - accuracy: 0.8833\n",
      "Epoch 192/300\n",
      "30/30 [==============================] - 0s 758us/step - loss: 0.3813 - accuracy: 0.8278\n",
      "Epoch 193/300\n",
      "30/30 [==============================] - 0s 828us/step - loss: 0.3754 - accuracy: 0.8667\n",
      "Epoch 194/300\n",
      "30/30 [==============================] - 0s 761us/step - loss: 0.4452 - accuracy: 0.8000\n",
      "Epoch 195/300\n",
      "30/30 [==============================] - 0s 827us/step - loss: 0.3462 - accuracy: 0.8556\n",
      "Epoch 196/300\n",
      "30/30 [==============================] - 0s 789us/step - loss: 0.3729 - accuracy: 0.8333\n",
      "Epoch 197/300\n",
      "30/30 [==============================] - 0s 724us/step - loss: 0.3830 - accuracy: 0.8444\n",
      "Epoch 198/300\n",
      "30/30 [==============================] - 0s 764us/step - loss: 0.4129 - accuracy: 0.8333\n",
      "Epoch 199/300\n",
      "30/30 [==============================] - 0s 793us/step - loss: 0.3286 - accuracy: 0.8556\n",
      "Epoch 200/300\n",
      "30/30 [==============================] - 0s 759us/step - loss: 0.3665 - accuracy: 0.8278\n",
      "Epoch 201/300\n",
      "30/30 [==============================] - 0s 759us/step - loss: 0.3186 - accuracy: 0.8611\n",
      "Epoch 202/300\n",
      "30/30 [==============================] - 0s 794us/step - loss: 0.3531 - accuracy: 0.8278\n",
      "Epoch 203/300\n",
      "30/30 [==============================] - 0s 758us/step - loss: 0.3241 - accuracy: 0.8389\n",
      "Epoch 204/300\n",
      "30/30 [==============================] - 0s 827us/step - loss: 0.3633 - accuracy: 0.8444\n",
      "Epoch 205/300\n",
      "30/30 [==============================] - 0s 724us/step - loss: 0.3608 - accuracy: 0.8278\n",
      "Epoch 206/300\n",
      "30/30 [==============================] - 0s 810us/step - loss: 0.3049 - accuracy: 0.8944\n",
      "Epoch 207/300\n",
      "30/30 [==============================] - 0s 758us/step - loss: 0.3336 - accuracy: 0.8611\n",
      "Epoch 208/300\n",
      "30/30 [==============================] - 0s 759us/step - loss: 0.3613 - accuracy: 0.8500\n",
      "Epoch 209/300\n",
      "30/30 [==============================] - 0s 828us/step - loss: 0.3373 - accuracy: 0.8556\n",
      "Epoch 210/300\n",
      "30/30 [==============================] - 0s 811us/step - loss: 0.3364 - accuracy: 0.8556\n",
      "Epoch 211/300\n",
      "30/30 [==============================] - 0s 793us/step - loss: 0.3273 - accuracy: 0.8556\n",
      "Epoch 212/300\n",
      "30/30 [==============================] - 0s 793us/step - loss: 0.3507 - accuracy: 0.8444\n",
      "Epoch 213/300\n",
      "30/30 [==============================] - 0s 759us/step - loss: 0.3324 - accuracy: 0.8389\n",
      "Epoch 214/300\n",
      "30/30 [==============================] - 0s 796us/step - loss: 0.3732 - accuracy: 0.8333\n",
      "Epoch 215/300\n",
      "30/30 [==============================] - 0s 759us/step - loss: 0.3027 - accuracy: 0.8778\n",
      "Epoch 216/300\n",
      "30/30 [==============================] - 0s 828us/step - loss: 0.3565 - accuracy: 0.8444\n",
      "Epoch 217/300\n",
      "30/30 [==============================] - 0s 862us/step - loss: 0.3335 - accuracy: 0.8778\n",
      "Epoch 218/300\n",
      "30/30 [==============================] - 0s 831us/step - loss: 0.2637 - accuracy: 0.9056\n",
      "Epoch 219/300\n",
      "30/30 [==============================] - 0s 793us/step - loss: 0.2944 - accuracy: 0.8833\n",
      "Epoch 220/300\n",
      "30/30 [==============================] - 0s 793us/step - loss: 0.3471 - accuracy: 0.8833\n",
      "Epoch 221/300\n",
      "30/30 [==============================] - 0s 811us/step - loss: 0.3526 - accuracy: 0.8389\n",
      "Epoch 222/300\n",
      "30/30 [==============================] - 0s 793us/step - loss: 0.3258 - accuracy: 0.8389\n",
      "Epoch 223/300\n",
      "30/30 [==============================] - 0s 759us/step - loss: 0.3911 - accuracy: 0.8278\n",
      "Epoch 224/300\n",
      "30/30 [==============================] - 0s 793us/step - loss: 0.3236 - accuracy: 0.8556\n",
      "Epoch 225/300\n",
      "30/30 [==============================] - 0s 845us/step - loss: 0.3052 - accuracy: 0.8778\n",
      "Epoch 226/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3899 - accuracy: 0.8000\n",
      "Epoch 227/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2730 - accuracy: 0.8833\n",
      "Epoch 228/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2637 - accuracy: 0.8944\n",
      "Epoch 229/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3259 - accuracy: 0.8444\n",
      "Epoch 230/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3514 - accuracy: 0.8556\n",
      "Epoch 231/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4088 - accuracy: 0.8389\n",
      "Epoch 232/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3012 - accuracy: 0.8667\n",
      "Epoch 233/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3890 - accuracy: 0.8389\n",
      "Epoch 234/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3014 - accuracy: 0.8667\n",
      "Epoch 235/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2633 - accuracy: 0.8833\n",
      "Epoch 236/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3256 - accuracy: 0.8611\n",
      "Epoch 237/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3331 - accuracy: 0.8722\n",
      "Epoch 238/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3243 - accuracy: 0.8611\n",
      "Epoch 239/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3658 - accuracy: 0.8667\n",
      "Epoch 240/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2935 - accuracy: 0.9000\n",
      "Epoch 241/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2665 - accuracy: 0.8833\n",
      "Epoch 242/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3262 - accuracy: 0.8556\n",
      "Epoch 243/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3119 - accuracy: 0.8722\n",
      "Epoch 244/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3381 - accuracy: 0.8389\n",
      "Epoch 245/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2907 - accuracy: 0.9000\n",
      "Epoch 246/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3127 - accuracy: 0.8667\n",
      "Epoch 247/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2939 - accuracy: 0.8889\n",
      "Epoch 248/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3055 - accuracy: 0.8833\n",
      "Epoch 249/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3879 - accuracy: 0.8389\n",
      "Epoch 250/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3749 - accuracy: 0.8611\n",
      "Epoch 251/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3032 - accuracy: 0.8667\n",
      "Epoch 252/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2793 - accuracy: 0.9056\n",
      "Epoch 253/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2906 - accuracy: 0.8833\n",
      "Epoch 254/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2359 - accuracy: 0.9222\n",
      "Epoch 255/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2959 - accuracy: 0.8833\n",
      "Epoch 256/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2854 - accuracy: 0.8833\n",
      "Epoch 257/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2893 - accuracy: 0.8833\n",
      "Epoch 258/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3954 - accuracy: 0.8278\n",
      "Epoch 259/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3358 - accuracy: 0.8722\n",
      "Epoch 260/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2933 - accuracy: 0.8944\n",
      "Epoch 261/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3366 - accuracy: 0.8667\n",
      "Epoch 262/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2781 - accuracy: 0.8889\n",
      "Epoch 263/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2211 - accuracy: 0.9111\n",
      "Epoch 264/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2968 - accuracy: 0.8778\n",
      "Epoch 265/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3407 - accuracy: 0.8389\n",
      "Epoch 266/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3196 - accuracy: 0.8778\n",
      "Epoch 267/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2759 - accuracy: 0.8778\n",
      "Epoch 268/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2822 - accuracy: 0.8778\n",
      "Epoch 269/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2794 - accuracy: 0.8889\n",
      "Epoch 270/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3308 - accuracy: 0.8556\n",
      "Epoch 271/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2783 - accuracy: 0.8889\n",
      "Epoch 272/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2611 - accuracy: 0.8667\n",
      "Epoch 273/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2701 - accuracy: 0.8833\n",
      "Epoch 274/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2580 - accuracy: 0.8778\n",
      "Epoch 275/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3036 - accuracy: 0.8778\n",
      "Epoch 276/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2700 - accuracy: 0.8944\n",
      "Epoch 277/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3226 - accuracy: 0.8556\n",
      "Epoch 278/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3006 - accuracy: 0.8556\n",
      "Epoch 279/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2747 - accuracy: 0.8667\n",
      "Epoch 280/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3211 - accuracy: 0.8611\n",
      "Epoch 281/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3195 - accuracy: 0.8556\n",
      "Epoch 282/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2734 - accuracy: 0.8667\n",
      "Epoch 283/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2725 - accuracy: 0.8667\n",
      "Epoch 284/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2907 - accuracy: 0.8778\n",
      "Epoch 285/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3214 - accuracy: 0.8500\n",
      "Epoch 286/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2871 - accuracy: 0.8889\n",
      "Epoch 287/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3328 - accuracy: 0.8444\n",
      "Epoch 288/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4157 - accuracy: 0.8556\n",
      "Epoch 289/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3662 - accuracy: 0.8222\n",
      "Epoch 290/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2837 - accuracy: 0.8889\n",
      "Epoch 291/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2878 - accuracy: 0.8778\n",
      "Epoch 292/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3772 - accuracy: 0.8389\n",
      "Epoch 293/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2356 - accuracy: 0.8889\n",
      "Epoch 294/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2608 - accuracy: 0.8778\n",
      "Epoch 295/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2115 - accuracy: 0.9222\n",
      "Epoch 296/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2525 - accuracy: 0.8889\n",
      "Epoch 297/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3223 - accuracy: 0.8833\n",
      "Epoch 298/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2780 - accuracy: 0.8833\n",
      "Epoch 299/300\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3070 - accuracy: 0.8611\n",
      "Epoch 300/300\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2493 - accuracy: 0.8944\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x19bd14aa400>"
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "\n",
    "model2.add(Input(30))\n",
    "\n",
    "model2.add(Dense(60, activation='tanh'))\n",
    "model2.add(Dropout(0.1))\n",
    "\n",
    "model2.add(Dense(60, activation='tanh'))\n",
    "model2.add(Dropout(0.4))\n",
    "\n",
    "model2.add(Dense(30, activation='tanh'))\n",
    "model2.add(Dropout(0.1))\n",
    "\n",
    "model2.add(Dense(30, activation='tanh'))\n",
    "model2.add(Dense(6, activation='sigmoid'))\n",
    "\n",
    "opt1 = Adam()\n",
    "model2.compile(optimizer=opt1, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model2.fit(train_features_tensor, train_targets_tensor, epochs=300, batch_size=6)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 1ms/step - loss: 0.1779 - accuracy: 0.9278\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.17791952192783356, 0.9277777671813965]"
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(train_features_tensor, train_targets_tensor)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step - loss: 0.2145 - accuracy: 0.9167\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.2145225554704666, 0.9166666865348816]"
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(test_features_tensor, test_targets_tensor)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
