{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam, RMSprop, SGD, Adadelta, Adamax, Adagrad, Nadam, Ftrl\n",
    "from keras.layers import Dense, Input\n",
    "import kerastuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "outputs": [
    {
     "data": {
      "text/plain": "   Age Sex ChestPainType  RestingBP  Cholesterol  FastingBS RestingECG  MaxHR  \\\n0   40   M           ATA        140          289          0     Normal    172   \n1   49   F           NAP        160          180          0     Normal    156   \n2   37   M           ATA        130          283          0         ST     98   \n3   48   F           ASY        138          214          0     Normal    108   \n4   54   M           NAP        150          195          0     Normal    122   \n\n  ExerciseAngina  Oldpeak ST_Slope  HeartDisease  \n0              N      0.0       Up             0  \n1              N      1.0     Flat             1  \n2              N      0.0       Up             0  \n3              Y      1.5     Flat             1  \n4              N      0.0       Up             0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>Sex</th>\n      <th>ChestPainType</th>\n      <th>RestingBP</th>\n      <th>Cholesterol</th>\n      <th>FastingBS</th>\n      <th>RestingECG</th>\n      <th>MaxHR</th>\n      <th>ExerciseAngina</th>\n      <th>Oldpeak</th>\n      <th>ST_Slope</th>\n      <th>HeartDisease</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>40</td>\n      <td>M</td>\n      <td>ATA</td>\n      <td>140</td>\n      <td>289</td>\n      <td>0</td>\n      <td>Normal</td>\n      <td>172</td>\n      <td>N</td>\n      <td>0.0</td>\n      <td>Up</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>49</td>\n      <td>F</td>\n      <td>NAP</td>\n      <td>160</td>\n      <td>180</td>\n      <td>0</td>\n      <td>Normal</td>\n      <td>156</td>\n      <td>N</td>\n      <td>1.0</td>\n      <td>Flat</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>37</td>\n      <td>M</td>\n      <td>ATA</td>\n      <td>130</td>\n      <td>283</td>\n      <td>0</td>\n      <td>ST</td>\n      <td>98</td>\n      <td>N</td>\n      <td>0.0</td>\n      <td>Up</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>48</td>\n      <td>F</td>\n      <td>ASY</td>\n      <td>138</td>\n      <td>214</td>\n      <td>0</td>\n      <td>Normal</td>\n      <td>108</td>\n      <td>Y</td>\n      <td>1.5</td>\n      <td>Flat</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>54</td>\n      <td>M</td>\n      <td>NAP</td>\n      <td>150</td>\n      <td>195</td>\n      <td>0</td>\n      <td>Normal</td>\n      <td>122</td>\n      <td>N</td>\n      <td>0.0</td>\n      <td>Up</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(r'C:\\Users\\marku\\Desktop\\ML\\MLGit\\datasets\\heart2.csv')\n",
    "dataset.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [],
   "source": [
    "features = dataset.drop('HeartDisease',axis=1)\n",
    "targets = dataset['HeartDisease']\n",
    "\n",
    "targets_onehot = pd.get_dummies(targets)\n",
    "features_onehot = pd.get_dummies(features)\n",
    "targets_onehot = targets_onehot.astype('float32')\n",
    "features_onehot = features_onehot.astype('float32')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "outputs": [],
   "source": [
    "features_onehot = normalize(features_onehot)\n",
    "\n",
    "train_features, test_features, train_targets, test_targets = train_test_split(features_onehot, targets_onehot, test_size=0.1, stratify=targets, random_state=42)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "outputs": [],
   "source": [
    "train_features_tensor = tf.convert_to_tensor(train_features)\n",
    "test_features_tensor = tf.convert_to_tensor(test_features)\n",
    "train_targets_tensor = tf.convert_to_tensor(train_targets)\n",
    "test_targets_tensor = tf.convert_to_tensor(test_targets)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Input(20))\n",
    "model.add(Dense(40, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(40, activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(2, activation='sigmoid'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "outputs": [],
   "source": [
    "opt1 = Adam()\n",
    "opt2 = RMSprop()\n",
    "opt3 = SGD()\n",
    "opt4 = Adadelta()\n",
    "opt5 = Adamax()\n",
    "opt6 = Adagrad()\n",
    "opt7 = Nadam()\n",
    "opt8 = Ftrl()\n",
    "model.compile(optimizer=opt2, loss='binary_crossentropy', metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "83/83 [==============================] - 1s 732us/step - loss: 0.6685 - accuracy: 0.5484\n",
      "Epoch 2/500\n",
      "83/83 [==============================] - 0s 720us/step - loss: 0.6308 - accuracy: 0.6077\n",
      "Epoch 3/500\n",
      "83/83 [==============================] - 0s 707us/step - loss: 0.6101 - accuracy: 0.6864\n",
      "Epoch 4/500\n",
      "83/83 [==============================] - 0s 720us/step - loss: 0.5913 - accuracy: 0.6864\n",
      "Epoch 5/500\n",
      "83/83 [==============================] - 0s 753us/step - loss: 0.5706 - accuracy: 0.7119\n",
      "Epoch 6/500\n",
      "83/83 [==============================] - 0s 707us/step - loss: 0.5531 - accuracy: 0.7349\n",
      "Epoch 7/500\n",
      "83/83 [==============================] - 0s 707us/step - loss: 0.5370 - accuracy: 0.7385\n",
      "Epoch 8/500\n",
      "83/83 [==============================] - 0s 720us/step - loss: 0.5244 - accuracy: 0.7446\n",
      "Epoch 9/500\n",
      "83/83 [==============================] - 0s 695us/step - loss: 0.5185 - accuracy: 0.7397\n",
      "Epoch 10/500\n",
      "83/83 [==============================] - 0s 732us/step - loss: 0.5068 - accuracy: 0.7663\n",
      "Epoch 11/500\n",
      "83/83 [==============================] - 0s 695us/step - loss: 0.4991 - accuracy: 0.7603\n",
      "Epoch 12/500\n",
      "83/83 [==============================] - 0s 671us/step - loss: 0.4938 - accuracy: 0.7700\n",
      "Epoch 13/500\n",
      "83/83 [==============================] - 0s 683us/step - loss: 0.4805 - accuracy: 0.7821\n",
      "Epoch 14/500\n",
      "83/83 [==============================] - 0s 695us/step - loss: 0.4688 - accuracy: 0.7942\n",
      "Epoch 15/500\n",
      "83/83 [==============================] - 0s 720us/step - loss: 0.4580 - accuracy: 0.8027\n",
      "Epoch 16/500\n",
      "83/83 [==============================] - 0s 780us/step - loss: 0.4412 - accuracy: 0.8039\n",
      "Epoch 17/500\n",
      "83/83 [==============================] - 0s 810us/step - loss: 0.4321 - accuracy: 0.8075\n",
      "Epoch 18/500\n",
      "83/83 [==============================] - 0s 805us/step - loss: 0.4240 - accuracy: 0.8257\n",
      "Epoch 19/500\n",
      "83/83 [==============================] - 0s 768us/step - loss: 0.4152 - accuracy: 0.8111\n",
      "Epoch 20/500\n",
      "83/83 [==============================] - 0s 754us/step - loss: 0.4047 - accuracy: 0.8329\n",
      "Epoch 21/500\n",
      "83/83 [==============================] - 0s 683us/step - loss: 0.3923 - accuracy: 0.8426\n",
      "Epoch 22/500\n",
      "83/83 [==============================] - 0s 764us/step - loss: 0.3901 - accuracy: 0.8341\n",
      "Epoch 23/500\n",
      "83/83 [==============================] - 0s 720us/step - loss: 0.3849 - accuracy: 0.8426\n",
      "Epoch 24/500\n",
      "83/83 [==============================] - 0s 707us/step - loss: 0.3874 - accuracy: 0.8269\n",
      "Epoch 25/500\n",
      "83/83 [==============================] - 0s 719us/step - loss: 0.3747 - accuracy: 0.8402\n",
      "Epoch 26/500\n",
      "83/83 [==============================] - 0s 671us/step - loss: 0.3682 - accuracy: 0.8499\n",
      "Epoch 27/500\n",
      "83/83 [==============================] - 0s 693us/step - loss: 0.3730 - accuracy: 0.8462\n",
      "Epoch 28/500\n",
      "83/83 [==============================] - 0s 671us/step - loss: 0.3694 - accuracy: 0.8390\n",
      "Epoch 29/500\n",
      "83/83 [==============================] - 0s 671us/step - loss: 0.3680 - accuracy: 0.8547\n",
      "Epoch 30/500\n",
      "83/83 [==============================] - 0s 695us/step - loss: 0.3642 - accuracy: 0.8511\n",
      "Epoch 31/500\n",
      "83/83 [==============================] - 0s 695us/step - loss: 0.3549 - accuracy: 0.8523\n",
      "Epoch 32/500\n",
      "83/83 [==============================] - 0s 695us/step - loss: 0.3557 - accuracy: 0.8608\n",
      "Epoch 33/500\n",
      "83/83 [==============================] - 0s 695us/step - loss: 0.3621 - accuracy: 0.8535\n",
      "Epoch 34/500\n",
      "83/83 [==============================] - 0s 720us/step - loss: 0.3696 - accuracy: 0.8426\n",
      "Epoch 35/500\n",
      "83/83 [==============================] - 0s 695us/step - loss: 0.3532 - accuracy: 0.8499\n",
      "Epoch 36/500\n",
      "83/83 [==============================] - 0s 720us/step - loss: 0.3471 - accuracy: 0.8608\n",
      "Epoch 37/500\n",
      "83/83 [==============================] - 0s 719us/step - loss: 0.3517 - accuracy: 0.8584\n",
      "Epoch 38/500\n",
      "83/83 [==============================] - 0s 695us/step - loss: 0.3571 - accuracy: 0.8499\n",
      "Epoch 39/500\n",
      "83/83 [==============================] - 0s 720us/step - loss: 0.3553 - accuracy: 0.8438\n",
      "Epoch 40/500\n",
      "83/83 [==============================] - 0s 695us/step - loss: 0.3558 - accuracy: 0.8499\n",
      "Epoch 41/500\n",
      "83/83 [==============================] - 0s 750us/step - loss: 0.3485 - accuracy: 0.8559\n",
      "Epoch 42/500\n",
      "83/83 [==============================] - 0s 658us/step - loss: 0.3491 - accuracy: 0.8571\n",
      "Epoch 43/500\n",
      "83/83 [==============================] - 0s 683us/step - loss: 0.3547 - accuracy: 0.8487\n",
      "Epoch 44/500\n",
      "83/83 [==============================] - 0s 719us/step - loss: 0.3457 - accuracy: 0.8644\n",
      "Epoch 45/500\n",
      "83/83 [==============================] - 0s 732us/step - loss: 0.3441 - accuracy: 0.8547\n",
      "Epoch 46/500\n",
      "83/83 [==============================] - 0s 758us/step - loss: 0.3509 - accuracy: 0.8535\n",
      "Epoch 47/500\n",
      "83/83 [==============================] - 0s 683us/step - loss: 0.3516 - accuracy: 0.8487\n",
      "Epoch 48/500\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.3514 - accuracy: 0.8523\n",
      "Epoch 49/500\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.3504 - accuracy: 0.8608\n",
      "Epoch 50/500\n",
      "83/83 [==============================] - 0s 861us/step - loss: 0.3360 - accuracy: 0.8608\n",
      "Epoch 51/500\n",
      "83/83 [==============================] - 0s 683us/step - loss: 0.3492 - accuracy: 0.8596\n",
      "Epoch 52/500\n",
      "83/83 [==============================] - 0s 707us/step - loss: 0.3356 - accuracy: 0.8656\n",
      "Epoch 53/500\n",
      "83/83 [==============================] - 0s 695us/step - loss: 0.3433 - accuracy: 0.8656\n",
      "Epoch 54/500\n",
      "83/83 [==============================] - 0s 695us/step - loss: 0.3355 - accuracy: 0.8608\n",
      "Epoch 55/500\n",
      "83/83 [==============================] - 0s 707us/step - loss: 0.3355 - accuracy: 0.8571\n",
      "Epoch 56/500\n",
      "83/83 [==============================] - 0s 695us/step - loss: 0.3446 - accuracy: 0.8559\n",
      "Epoch 57/500\n",
      "83/83 [==============================] - 0s 746us/step - loss: 0.3407 - accuracy: 0.8596\n",
      "Epoch 58/500\n",
      "83/83 [==============================] - 0s 683us/step - loss: 0.3404 - accuracy: 0.8620\n",
      "Epoch 59/500\n",
      "83/83 [==============================] - 0s 695us/step - loss: 0.3394 - accuracy: 0.8584\n",
      "Epoch 60/500\n",
      "83/83 [==============================] - 0s 680us/step - loss: 0.3333 - accuracy: 0.8656\n",
      "Epoch 61/500\n",
      "83/83 [==============================] - 0s 658us/step - loss: 0.3304 - accuracy: 0.8596\n",
      "Epoch 62/500\n",
      "83/83 [==============================] - 0s 683us/step - loss: 0.3454 - accuracy: 0.8596\n",
      "Epoch 63/500\n",
      "83/83 [==============================] - 0s 695us/step - loss: 0.3387 - accuracy: 0.8608\n",
      "Epoch 64/500\n",
      "83/83 [==============================] - 0s 695us/step - loss: 0.3344 - accuracy: 0.8680\n",
      "Epoch 65/500\n",
      "83/83 [==============================] - 0s 744us/step - loss: 0.3278 - accuracy: 0.8668\n",
      "Epoch 66/500\n",
      "83/83 [==============================] - 0s 671us/step - loss: 0.3394 - accuracy: 0.8620\n",
      "Epoch 67/500\n",
      "83/83 [==============================] - 0s 804us/step - loss: 0.3357 - accuracy: 0.8656\n",
      "Epoch 68/500\n",
      "83/83 [==============================] - 0s 744us/step - loss: 0.3328 - accuracy: 0.8571\n",
      "Epoch 69/500\n",
      "83/83 [==============================] - 0s 707us/step - loss: 0.3289 - accuracy: 0.8680\n",
      "Epoch 70/500\n",
      "83/83 [==============================] - 0s 707us/step - loss: 0.3342 - accuracy: 0.8644\n",
      "Epoch 71/500\n",
      "83/83 [==============================] - 0s 646us/step - loss: 0.3302 - accuracy: 0.8632\n",
      "Epoch 72/500\n",
      "83/83 [==============================] - 0s 634us/step - loss: 0.3397 - accuracy: 0.8547\n",
      "Epoch 73/500\n",
      "83/83 [==============================] - 0s 668us/step - loss: 0.3425 - accuracy: 0.8632\n",
      "Epoch 74/500\n",
      "83/83 [==============================] - 0s 646us/step - loss: 0.3328 - accuracy: 0.8644\n",
      "Epoch 75/500\n",
      "83/83 [==============================] - 0s 598us/step - loss: 0.3350 - accuracy: 0.8692\n",
      "Epoch 76/500\n",
      "83/83 [==============================] - 0s 634us/step - loss: 0.3369 - accuracy: 0.8547\n",
      "Epoch 77/500\n",
      "83/83 [==============================] - 0s 634us/step - loss: 0.3285 - accuracy: 0.8608\n",
      "Epoch 78/500\n",
      "83/83 [==============================] - 0s 646us/step - loss: 0.3299 - accuracy: 0.8632\n",
      "Epoch 79/500\n",
      "83/83 [==============================] - 0s 719us/step - loss: 0.3256 - accuracy: 0.8608\n",
      "Epoch 80/500\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.3335 - accuracy: 0.8596\n",
      "Epoch 81/500\n",
      "83/83 [==============================] - 0s 939us/step - loss: 0.3291 - accuracy: 0.8692\n",
      "Epoch 82/500\n",
      "83/83 [==============================] - 0s 683us/step - loss: 0.3177 - accuracy: 0.8656\n",
      "Epoch 83/500\n",
      "83/83 [==============================] - 0s 643us/step - loss: 0.3327 - accuracy: 0.8584\n",
      "Epoch 84/500\n",
      "83/83 [==============================] - 0s 671us/step - loss: 0.3380 - accuracy: 0.8668\n",
      "Epoch 85/500\n",
      "83/83 [==============================] - 0s 646us/step - loss: 0.3342 - accuracy: 0.8608\n",
      "Epoch 86/500\n",
      "83/83 [==============================] - 0s 634us/step - loss: 0.3317 - accuracy: 0.8668\n",
      "Epoch 87/500\n",
      "83/83 [==============================] - 0s 634us/step - loss: 0.3345 - accuracy: 0.8668\n",
      "Epoch 88/500\n",
      "83/83 [==============================] - 0s 622us/step - loss: 0.3224 - accuracy: 0.8632\n",
      "Epoch 89/500\n",
      "83/83 [==============================] - 0s 691us/step - loss: 0.3272 - accuracy: 0.8644\n",
      "Epoch 90/500\n",
      "83/83 [==============================] - 0s 646us/step - loss: 0.3309 - accuracy: 0.8596\n",
      "Epoch 91/500\n",
      "83/83 [==============================] - 0s 634us/step - loss: 0.3256 - accuracy: 0.8717\n",
      "Epoch 92/500\n",
      "83/83 [==============================] - 0s 634us/step - loss: 0.3203 - accuracy: 0.8705\n",
      "Epoch 93/500\n",
      "83/83 [==============================] - 0s 668us/step - loss: 0.3277 - accuracy: 0.8608\n",
      "Epoch 94/500\n",
      "83/83 [==============================] - 0s 671us/step - loss: 0.3259 - accuracy: 0.8596\n",
      "Epoch 95/500\n",
      "83/83 [==============================] - 0s 659us/step - loss: 0.3283 - accuracy: 0.8668\n",
      "Epoch 96/500\n",
      "83/83 [==============================] - 0s 683us/step - loss: 0.3275 - accuracy: 0.8608\n",
      "Epoch 97/500\n",
      "83/83 [==============================] - 0s 634us/step - loss: 0.3317 - accuracy: 0.8608\n",
      "Epoch 98/500\n",
      "83/83 [==============================] - 0s 634us/step - loss: 0.3284 - accuracy: 0.8584\n",
      "Epoch 99/500\n",
      "83/83 [==============================] - 0s 718us/step - loss: 0.3248 - accuracy: 0.8680\n",
      "Epoch 100/500\n",
      "83/83 [==============================] - 0s 622us/step - loss: 0.3357 - accuracy: 0.8571\n",
      "Epoch 101/500\n",
      "83/83 [==============================] - 0s 646us/step - loss: 0.3280 - accuracy: 0.8729\n",
      "Epoch 102/500\n",
      "83/83 [==============================] - 0s 659us/step - loss: 0.3263 - accuracy: 0.8571\n",
      "Epoch 103/500\n",
      "83/83 [==============================] - 0s 655us/step - loss: 0.3203 - accuracy: 0.8692\n",
      "Epoch 104/500\n",
      "83/83 [==============================] - 0s 622us/step - loss: 0.3216 - accuracy: 0.8705\n",
      "Epoch 105/500\n",
      "83/83 [==============================] - 0s 685us/step - loss: 0.3174 - accuracy: 0.8705\n",
      "Epoch 106/500\n",
      "83/83 [==============================] - 0s 622us/step - loss: 0.3248 - accuracy: 0.8680\n",
      "Epoch 107/500\n",
      "83/83 [==============================] - 0s 659us/step - loss: 0.3293 - accuracy: 0.8692\n",
      "Epoch 108/500\n",
      "83/83 [==============================] - 0s 646us/step - loss: 0.3215 - accuracy: 0.8644\n",
      "Epoch 109/500\n",
      "83/83 [==============================] - 0s 631us/step - loss: 0.3214 - accuracy: 0.8644\n",
      "Epoch 110/500\n",
      "83/83 [==============================] - 0s 646us/step - loss: 0.3157 - accuracy: 0.8668\n",
      "Epoch 111/500\n",
      "83/83 [==============================] - 0s 646us/step - loss: 0.3247 - accuracy: 0.8632\n",
      "Epoch 112/500\n",
      "83/83 [==============================] - 0s 634us/step - loss: 0.3233 - accuracy: 0.8644\n",
      "Epoch 113/500\n",
      "83/83 [==============================] - 0s 671us/step - loss: 0.3131 - accuracy: 0.8729\n",
      "Epoch 114/500\n",
      "83/83 [==============================] - 0s 742us/step - loss: 0.3224 - accuracy: 0.8656\n",
      "Epoch 115/500\n",
      "83/83 [==============================] - 0s 646us/step - loss: 0.3188 - accuracy: 0.8656\n",
      "Epoch 116/500\n",
      "83/83 [==============================] - 0s 646us/step - loss: 0.3145 - accuracy: 0.8656\n",
      "Epoch 117/500\n",
      "83/83 [==============================] - 0s 671us/step - loss: 0.3163 - accuracy: 0.8729\n",
      "Epoch 118/500\n",
      "83/83 [==============================] - 0s 644us/step - loss: 0.3276 - accuracy: 0.8644\n",
      "Epoch 119/500\n",
      "83/83 [==============================] - 0s 646us/step - loss: 0.3186 - accuracy: 0.8717\n",
      "Epoch 120/500\n",
      "83/83 [==============================] - 0s 646us/step - loss: 0.3260 - accuracy: 0.8717\n",
      "Epoch 121/500\n",
      "83/83 [==============================] - 0s 659us/step - loss: 0.3258 - accuracy: 0.8717\n",
      "Epoch 122/500\n",
      "83/83 [==============================] - 0s 622us/step - loss: 0.3201 - accuracy: 0.8608\n",
      "Epoch 123/500\n",
      "83/83 [==============================] - 0s 659us/step - loss: 0.3157 - accuracy: 0.8620\n",
      "Epoch 124/500\n",
      "83/83 [==============================] - 0s 622us/step - loss: 0.3227 - accuracy: 0.8729\n",
      "Epoch 125/500\n",
      "83/83 [==============================] - 0s 646us/step - loss: 0.3098 - accuracy: 0.8680\n",
      "Epoch 126/500\n",
      "83/83 [==============================] - 0s 610us/step - loss: 0.3209 - accuracy: 0.8705\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x190b10c5820>"
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=25, mode='auto')\n",
    "model.fit(train_features_tensor, train_targets_tensor, epochs=500, batch_size=10, callbacks=[callback])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 1ms/step - loss: 0.2634 - accuracy: 0.9348\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.2634010314941406, 0.9347826242446899]"
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_features_tensor, test_targets_tensor)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
